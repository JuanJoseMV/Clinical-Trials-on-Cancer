{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import preprocessing # LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler # Escala los datos\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import scikitplot as skplt \n",
    "from string import ascii_uppercase \n",
    "# import seaborn as sns\n",
    "import qgrid\n",
    "import time\n",
    "#from sklearn.externals import joblib # Para guardar el modelo\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "from scipy import stats #Para la moda\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCSV(pathSamples, pathMatrix):\n",
    "    df_loaded = pd.read_table(pathMatrix, sep=',')\n",
    "    data = pd.read_table(pathSamples, sep=',')\n",
    "    clin_trial_values = df_loaded.values\n",
    "    \n",
    "    Y = data['Eligible']\n",
    "    Y = Y.astype(int)\n",
    "    X = clin_trial_values[:, :]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_error(y_est, y_real):\n",
    "    err = 0\n",
    "    for y_e, y_r in zip(y_est, y_real):\n",
    "\n",
    "        if y_e != y_r:\n",
    "            err += 1\n",
    "\n",
    "    return err/np.size(y_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(Xtest, Ytest, probs, xlabel):\n",
    "    ns_probs = [0 for _ in range(len(Ytest))]\n",
    "    \n",
    "    probs = probs[:, 1]\n",
    "    ns_auc = roc_auc_score(Ytest, ns_probs)\n",
    "    auc = roc_auc_score(Ytest, probs)  \n",
    "\n",
    "    print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "    print('Logistic: ROC AUC=%.3f' % (auc))\n",
    "\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(Ytest, ns_probs)\n",
    "    fpr, tpr, _ = roc_curve(Ytest, probs)   \n",
    "\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "    plt.plot(fpr, tpr, marker='.', label= xlabel)\n",
    "\n",
    "    # axis labels\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_SVC(ker, C, gam, impresion = False):\n",
    "    \n",
    "    if gam == 0:\n",
    "        gam = 'auto'\n",
    "\n",
    "    svc = BaggingClassifier(SVC(gamma=gam, C=float(C),  kernel=ker, decision_function_shape='ovo' , probability = True))\n",
    "    tiempo_i = time.time()\n",
    "    \n",
    "    accuracy_list = np.zeros([4])\n",
    "    accuracy_list_train = np.zeros([4])\n",
    "    precision_list = np.zeros([4,2])\n",
    "    recall_list = np.zeros([4,2])\n",
    "    f_list = np.zeros([4,2]) \n",
    "    errores = np.zeros(4)\n",
    "    list_acc_mean = []\n",
    "    list_acc_train_mean = []\n",
    "    list_acc_std = []\n",
    "    list_acc_train_std = []\n",
    "    #list_percentage = [0.05,0.10,0.15,0.20,0.25,0.3]\n",
    "    list_percentage = [0.2]\n",
    "    \n",
    "    for i in list_percentage:\n",
    "        for j in range(4):\n",
    "            print(i, j)\n",
    "            Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=i)\n",
    "            scaler = MinMaxScaler()#Escala entre 0 y 1\n",
    "            Xtrain = scaler.fit_transform(Xtrain)\n",
    "            Xtest = scaler.transform(Xtest)\n",
    "\n",
    "            print('fitting')\n",
    "            svc.fit(Xtrain, Ytrain)\n",
    "            pred = svc.predict(Xtest)\n",
    "            pred_train = svc.predict(Xtrain)\n",
    "            print('done')\n",
    "\n",
    "            #code for calculating accuracy \n",
    "            _accuracy_ = accuracy_score(Ytest, pred, normalize=True)\n",
    "            accuracy_list[j] = _accuracy_\n",
    "            \n",
    "            _accuracy_train_ = accuracy_score(Ytrain, pred_train, normalize=True)\n",
    "            accuracy_list_train[j] = _accuracy_train_\n",
    "\n",
    "            #code for calculating recall \n",
    "            _recalls_ = recall_score(Ytest, pred, average=None)\n",
    "            recall_list[j] = _recalls_\n",
    "\n",
    "            #code for calculating precision \n",
    "            _precisions_ = precision_score(Ytest, pred, average=None)\n",
    "            precision_list[j] = _precisions_\n",
    "\n",
    "            _f_score_ = f1_score(Ytest, pred, average=None)\n",
    "            f_list[j] = _f_score_\n",
    "\n",
    "\n",
    "            errores[j] = classification_error(pred, Ytest)\n",
    "        \n",
    "        list_acc_mean.append(np.mean(accuracy_list))\n",
    "        list_acc_std.append(np.std(accuracy_list))\n",
    "        list_acc_train_mean.append(np.mean(accuracy_list_train))\n",
    "        list_acc_train_std.append(np.std(accuracy_list_train))\n",
    "       \n",
    "    \n",
    "    if impresion == True:\n",
    "        \n",
    "        x = [10000-(i* 10000) for i in list_percentage]\n",
    "        sneg = [m-s for m,s in zip(list_acc_mean,list_acc_std)]\n",
    "        spos = [m+s for m,s in zip(list_acc_mean,list_acc_std)]\n",
    "        \n",
    "        sneg_train = [m-s for m,s in zip(list_acc_train_mean,list_acc_train_std)]\n",
    "        spos_train = [m+s for m,s in zip(list_acc_train_mean,list_acc_train_std)]\n",
    "        \n",
    "        fig1, ax1 = plt.subplots()\n",
    "        \n",
    "        ax1.fill_between(x,sneg_train,spos_train,alpha=.4)\n",
    "        ax1.plot(x, list_acc_train_mean, marker = 'v', label = \"train\")\n",
    "        ax1.fill_between(x,sneg,spos,alpha=.4)\n",
    "        ax1.plot(x, list_acc_mean, marker = 'p', label = \"test\")\n",
    "\n",
    "        ax1.set_xlabel(\"Samples in train\")\n",
    "        ax1.set_ylabel(\"Accuracy\")\n",
    "\n",
    "        ax1.legend(loc=\"upper right\", title=\"Learning curve\", frameon=False)\n",
    "        plt.show()\n",
    "        \n",
    "        #Curva ROC\n",
    "        \n",
    "        svc_probs = svc.predict_proba(Xtest)\n",
    "        \n",
    "        plot_roc(Xtest, Ytest, svc_probs, \"SVM\")\n",
    "        skplt.metrics.plot_confusion_matrix(Ytest, pred, normalize=True)\n",
    "\n",
    "    return str(np.mean(accuracy_list)), str(np.std(accuracy_list)), str(np.mean(recall_list)), str(np.std(recall_list)), str(np.mean(precision_list)), str(np.std(precision_list)), str(np.mean(f_list)), str(np.std(f_list)), str(np.mean(errores)), str(np.std(errores)), str(time.time()-tiempo_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA 10k_1Col_NoCarEsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = loadCSV(\"../../Dataset/10k_1Col_NoCarEsp_LSA.csv\", \"../../Tables/docsTopicsLSA1200.csv\") #Cargar SCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear 0.1 0.0 ...\n",
      "0.2 0\n",
      "fitting\n"
     ]
    }
   ],
   "source": [
    "# Llenar tabla con diferentes hiperparámetros\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "randn = np.random.randn\n",
    "df_types = pd.DataFrame({\n",
    "    'Kernel' : pd.Series(['linear','linear','linear','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf']),\n",
    "    'C' : pd.Series([0.1,0.5,1, 0.1,0.1,0.1,0.5,0.5,0.5,1,1,1]),\n",
    "    'gamma' : pd.Series([0,0,0, 0.1,0.5,1,0.1,0.5,1,0.1,0.5,1])})\n",
    "df_types[\"Eficiencia\"] = \"\"\n",
    "df_types[\"Int_Eficiencia\"] = \"\"\n",
    "df_types[\"Sensibilidad\"] = \"\"\n",
    "df_types[\"Int_Sensibilidad\"] = \"\"\n",
    "df_types[\"Precision\"] = \"\"\n",
    "df_types[\"Int_Precision\"] = \"\"\n",
    "df_types[\"F-Score\"] = \"\"\n",
    "df_types[\"Int_F-Score\"] = \"\"\n",
    "df_types[\"Error_Prueba\"] = \"\"\n",
    "df_types[\"Int_error\"] = \"\"\n",
    "df_types[\"Tiempo de ejecución\"] = \"\"\n",
    "df_types.set_index(['Kernel','C','gamma'], inplace=True)\n",
    "\n",
    "for n, k, o in df_types.index:\n",
    "    print(n,k,o, '...')\n",
    "    Acc, IntAcc, Sen, IntSen, Pre, IntPre, f, IntF, error, stdError, tiempo = model_SVC(n, k, o, impresion = False)\n",
    "    print('aa')\n",
    "    df_types[\"Eficiencia\"][n,k,o] = Acc\n",
    "    df_types[\"Int_Eficiencia\"][n,k,o] = IntAcc\n",
    "    df_types[\"Sensibilidad\"][n,k,o] = Sen\n",
    "    df_types[\"Int_Sensibilidad\"][n,k,o] = IntSen\n",
    "    df_types[\"Precision\"][n,k,o] = Pre\n",
    "    df_types[\"Int_Precision\"][n,k,o] = IntPre\n",
    "    df_types[\"F-Score\"][n,k,o] = f\n",
    "    df_types[\"Int_F-Score\"][n,k,o] = IntF\n",
    "    df_types[\"Error_Prueba\"][n,k,o] = error\n",
    "    df_types[\"Int_error\"][n,k,o] = stdError\n",
    "    df_types[\"Tiempo de ejecución\"][n,k,o] = tiempo\n",
    "\n",
    "\n",
    "#df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar función con el mejor modelo\n",
    "Acc, IntAcc, Sen, IntSen, Pre, IntPre, f, IntF, error, stdError, tiempo = model_SVC('rbf', 2, 1, impresion = True)\n",
    "print('Eficiencia',Acc, ' Int_Eficiencia', IntAcc,' Sensibilidad', Sen, ' Int_Sensibilidad',IntSen,' Precision', Pre, ' Int_Precision',IntPre,' F-Score', f, ' Int_F-Score',IntF,' Error_Prueba', error,' Int_Error', stdError,' Tiempo ejecución', tiempo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
