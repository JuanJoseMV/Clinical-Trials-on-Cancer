{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re # Expresiones regulares\n",
    "from sklearn import preprocessing # LabelEncoder\n",
    "import pickle #Guardado binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table(\"../Dataset/labeledEligibilitySample10k.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se transforma la variable elegible (la salida) en 0 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clin_trial = pd.DataFrame(np.array(data).reshape(10000,1), columns=['Description'])\n",
    "#clin_trial[:].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clin_trial['Num'], clin_trial['ExtraPart'] = clin_trial['Description'].str.split(',', 1).str\n",
    "clin_trial=clin_trial.drop(['Num'], axis=1)\n",
    "\n",
    "clin_trial['Label'], clin_trial['TrashPart'] = clin_trial['ExtraPart'].str.split(',', 1).str\n",
    "clin_trial['Eligible'] = clin_trial['Label'].str.extract('(\\d)', expand=True)\n",
    "clin_trial=clin_trial.drop(['Label'], axis=1)\n",
    "clin_trial=clin_trial.drop(['ExtraPart'], axis=1)\n",
    "\n",
    "clin_trial['Interventions'], clin_trial['Diagnoses'] = clin_trial['TrashPart'].str.split('.', 1).str\n",
    "clin_trial=clin_trial.drop(['TrashPart'], axis=1)\n",
    "\n",
    "clin_trial=clin_trial.drop(['Description'], axis=1)\n",
    "\n",
    "#clin_trial.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eligible</th>\n",
       "      <th>Interventions</th>\n",
       "      <th>Diagnoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2131</td>\n",
       "      <td>0</td>\n",
       "      <td>Prednisone</td>\n",
       "      <td>prostate cancer diagnosis and survival expect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8423</td>\n",
       "      <td>1</td>\n",
       "      <td>Hydroxychloroquine</td>\n",
       "      <td>uncontrolled intercurrent illness including b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9666</td>\n",
       "      <td>1</td>\n",
       "      <td>Lenvatinib</td>\n",
       "      <td>unresectable hepatocellular carcinoma hcc dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8439</td>\n",
       "      <td>1</td>\n",
       "      <td>Fludarabine</td>\n",
       "      <td>adult nasal type extranodal nk cell lymphoma ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>Interleukin-2</td>\n",
       "      <td>kidney cancer diagnosis and ecog performance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6712</td>\n",
       "      <td>1</td>\n",
       "      <td>Docetaxel</td>\n",
       "      <td>mucinous adenocarcinoma diagnosis and patient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8405</td>\n",
       "      <td>1</td>\n",
       "      <td>Mycophenolate mofetil</td>\n",
       "      <td>stage iii grade one follicular lymphoma diagn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>Pancrelipase</td>\n",
       "      <td>metastatic pancreatic cancer diagnosis and pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7953</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Antibodies, Monoclonal</td>\n",
       "      <td>brain cancer diagnosis and total bilirubin gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3247</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Antibodies, Monoclonal</td>\n",
       "      <td>recurrent grade three follicular lymphoma dia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Eligible             Interventions  \\\n",
       "2131        0               Prednisone    \n",
       "8423        1       Hydroxychloroquine    \n",
       "9666        1               Lenvatinib    \n",
       "8439        1              Fludarabine    \n",
       "197         0            Interleukin-2    \n",
       "6712        1                Docetaxel    \n",
       "8405        1    Mycophenolate mofetil    \n",
       "222         0             Pancrelipase    \n",
       "7953        1  \"Antibodies, Monoclonal    \n",
       "3247        0  \"Antibodies, Monoclonal    \n",
       "\n",
       "                                              Diagnoses  \n",
       "2131   prostate cancer diagnosis and survival expect...  \n",
       "8423   uncontrolled intercurrent illness including b...  \n",
       "9666   unresectable hepatocellular carcinoma hcc dia...  \n",
       "8439   adult nasal type extranodal nk cell lymphoma ...  \n",
       "197    kidney cancer diagnosis and ecog performance ...  \n",
       "6712   mucinous adenocarcinoma diagnosis and patient...  \n",
       "8405   stage iii grade one follicular lymphoma diagn...  \n",
       "222    metastatic pancreatic cancer diagnosis and pr...  \n",
       "7953   brain cancer diagnosis and total bilirubin gr...  \n",
       "3247   recurrent grade three follicular lymphoma dia...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se quita study interventions are puesto que está en todas las muestras de la varialbe Interventions\n",
    "clin_trial['Interventions'] = clin_trial['Interventions'].str.replace(\"study interventions are\\s\", \"\")\n",
    "clin_trial.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Se transforma todo a minúsculas\n",
    "clin_trial['Interventions'] = clin_trial['Interventions'].str.lower() ##Todo a minúscula\n",
    "clin_trial['Diagnoses'] = clin_trial['Diagnoses'].str.lower()     ##Todo a minúscula\n",
    "\n",
    "#Se reemplazan vocales con tildes en ambas variables\n",
    "clin_trial['Interventions'] = clin_trial['Interventions'].str.replace('[áäâà]', 'a', regex=True)\n",
    "clin_trial['Interventions'] = clin_trial['Interventions'].str.replace('[éêèë]', 'e', regex=True)\n",
    "clin_trial['Interventions'] = clin_trial['Interventions'].str.replace('[íïìî]', 'i', regex=True)\n",
    "clin_trial['Interventions'] = clin_trial['Interventions'].str.replace('[óôòö]', 'o', regex=True)\n",
    "clin_trial['Interventions'] = clin_trial['Interventions'].str.replace('[úûùü]', 'u', regex=True)\n",
    "clin_trial['Interventions'] = clin_trial['Interventions'].str.replace('[\"]', '', regex=True)\n",
    "\n",
    "clin_trial['Diagnoses'] = clin_trial['Diagnoses'].str.replace('[áäâà]', 'a', regex=True)\n",
    "clin_trial['Diagnoses'] = clin_trial['Diagnoses'].str.replace('[éêèë]', 'e', regex=True)\n",
    "clin_trial['Diagnoses'] = clin_trial['Diagnoses'].str.replace('[íïìî]', 'i', regex=True)\n",
    "clin_trial['Diagnoses'] = clin_trial['Diagnoses'].str.replace('[óôòö]', 'o', regex=True)\n",
    "clin_trial['Diagnoses'] = clin_trial['Diagnoses'].str.replace('[úûùü]', 'u', regex=True)\n",
    "clin_trial['Diagnoses'] = clin_trial['Diagnoses'].str.replace('^\\s', '', regex=True)\n",
    "clin_trial['Diagnoses'] = clin_trial['Diagnoses'].str.replace('[\"]', '', regex=True)\n",
    "clin_trial['Diagnoses'] = clin_trial['Diagnoses'].str.replace('[;]', '', regex=True)\n",
    "\n",
    "#clin_trial.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1426"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total de categorías diferentes en la variable Interventions\n",
    "len(np.unique(clin_trial['Interventions'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9786"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total de categorías diferentes en la variable Diagnoses\n",
    "len(np.unique(clin_trial['Diagnoses']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificación de la variable Interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.unique(clin_trial['Interventions'])\n",
    "\n",
    "lb_interventions = preprocessing.LabelEncoder()\n",
    "lb_interventions.fit(labels)\n",
    "clin_trial['Interventions'] = lb_interventions.transform(clin_trial['Interventions']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remover Stop Words\n",
    "\n",
    "## Preliminares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Se carga la libreria\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Se debe descargar el conjunto de 'Stop Words' la primera vez\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#Se carga la librería de lematización\n",
    "#PONER conda install -c conda-forge spacy EN ANACONDA PROMPT\n",
    "# Y python -m spacy download en_core_web_sm\n",
    "\n",
    "#Se carga la librería de lematización\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#Se carga la librería de stemming y se inicializa el stemmer\n",
    "import nltk\n",
    "from nltk import SnowballStemmer\n",
    "stemmer=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear las palabras Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematización\n",
    "\n",
    "\"Dada una forma flexionada (es decir, en plural, en femenino, conjugada, etc), hallar el lema correspondiente. El lema es la forma que por convenio se acepta como representante de todas las formas flexionadas de una misma palabra. Es decir, el lema de una palabra es la palabra que nos encontraríamos como entrada en un diccionario tradicional: singular para sustantivos, masculino singular para adjetivos, infinitivo para verbos.\" -Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/qu4nt/reducir-el-número-de-palabras-de-un-texto-lematización-y-radicalización-stemming-con-python-965bfd0c69fa\n",
    "toks = []\n",
    "\n",
    "for sample in clin_trial['Diagnoses']:\n",
    "    words = nlp(sample)\n",
    "    lemma = [tok.lemma_.lower() for tok in words]\n",
    "    #print(lemma)\n",
    "    toks.append(lemma)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar las Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga las Stop Words en inglés\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "## Estaría bien revisar este conjunto 'english'. Pero supongo que es el más útil para nuestro caso también.\n",
    "# Imprime algunas Stop Words\n",
    "#stop_words[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remover las Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for tok in toks:\n",
    "    clean_word = [word for word in tok if word not in stop_words]\n",
    "    tokens.append(clean_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "\"Es un método para reducir una palabra a su raíz o (en inglés) a un stem.\" - Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemms = []\n",
    "for tok in tokens:\n",
    "    var = [stemmer.stem(token) for token in tok]\n",
    "    stemms.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar las stemms\n",
    "\n",
    "fichero_stemms = open(\"archivo_stemms\", \"wb\")\n",
    "pickle.dump(stemms, fichero_stemms)\n",
    "\n",
    "fichero_stemms.close()\n",
    "del fichero_stemms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF \n",
    "Term frequency – Inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar los stemms\n",
    "\n",
    "fichero = open(\"archivo_stemms\", \"rb\")\n",
    "stemms = pickle.load(fichero)\n",
    "\n",
    "fichero.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmsT = [ ' '.join(stemms[item]) for item in range (len(stemms))] #Se transforma de lista de listas a una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(stemmsT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = vectorizer.get_feature_names()\n",
    "dense = X.todense()\n",
    "denselist = dense.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=denselist, columns= cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del clin_trial['Diagnoses']\n",
    "df = pd.concat([clin_trial, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf('df_prueba.h5', key = 'clin_trial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordenar y eliminar palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('df_prueba.h5', 'clin_trial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible = df['Eligible'].values #Para ver las palabras por clase\n",
    "\n",
    "dict_0 = {}\n",
    "dict_1 = {}\n",
    "\n",
    "for col in df:\n",
    "    if(col == 'Eligible' or col == 'Interventions'):\n",
    "        continue\n",
    "    ar = df[col].values\n",
    "    condlist = [(eligible == \"1\") & (ar != 0.0), (eligible == \"0\") & (ar != 0.0)]\n",
    "    choicelist = [1, 2]\n",
    "    res = np.select(condlist, choicelist)\n",
    "    \n",
    "    dict_0[col] = len(res[res==2])\n",
    "    dict_1[col] = len(res[res==1])\n",
    "    \n",
    "#     print(col + \" tiene \", len(res[res==2]), \" apariciones en la clase 0\")\n",
    "#     print(col + \" tiene \", len(res[res==1]), \" apariciones en la clase 1 \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_words = []\n",
    "for a,b in zip (dict_0, dict_1): #Para imprimir las palabras\n",
    "    if((dict_0[a]/(dict_0[a]+dict_1[b])<=0.35 or dict_0[a]/(dict_0[a]+dict_1[b])>=0.65) and (dict_0[a]+dict_1[b])>=12):\n",
    "#         anterior con 0.37, 0.63, 11\n",
    "#         print(dict_0[a]/(dict_0[a]+dict_1[b]))\n",
    "#print(a + \" tiene \", dict_0[a], \" muestras en la clase 0 \\n\" + b + \" tiene \", dict_1[b], \" muestras en la clase 1\")\n",
    "        final_words.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "657"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_words.insert(0,'Eligible')\n",
    "final_words.insert(1,'Interventions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = df\n",
    "for word in df:\n",
    "    if word not in final_words:\n",
    "        del aux[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 659)\n"
     ]
    }
   ],
   "source": [
    "print(aux.shape)\n",
    "df = aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5264 659\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_0), len(final_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eligible</th>\n",
       "      <th>Interventions</th>\n",
       "      <th>abdomin</th>\n",
       "      <th>abl</th>\n",
       "      <th>abscess</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absorpt</th>\n",
       "      <th>abstin</th>\n",
       "      <th>accord</th>\n",
       "      <th>accur</th>\n",
       "      <th>...</th>\n",
       "      <th>withdraw</th>\n",
       "      <th>within</th>\n",
       "      <th>woman</th>\n",
       "      <th>wort</th>\n",
       "      <th>would</th>\n",
       "      <th>wound</th>\n",
       "      <th>write</th>\n",
       "      <th>york</th>\n",
       "      <th>zero</th>\n",
       "      <th>zubrod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099676</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>1</td>\n",
       "      <td>1109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>1</td>\n",
       "      <td>1201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>1</td>\n",
       "      <td>939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>1</td>\n",
       "      <td>639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 659 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Eligible  Interventions  abdomin  abl  abscess  absolut  absorpt  abstin  \\\n",
       "0           0            464      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "1           0            101      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "2           0            349      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "3           0           1052      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "4           0            708      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "...       ...            ...      ...  ...      ...      ...      ...     ...   \n",
       "9995        1           1109      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "9996        1            200      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "9997        1           1201      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "9998        1            939      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "9999        1            639      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "\n",
       "      accord  accur  ...  withdraw    within  woman  wort  would     wound  \\\n",
       "0        0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.000000   \n",
       "1        0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.000000   \n",
       "2        0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.000000   \n",
       "3        0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.000000   \n",
       "4        0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.000000   \n",
       "...      ...    ...  ...       ...       ...    ...   ...    ...       ...   \n",
       "9995     0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.000000   \n",
       "9996     0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.000000   \n",
       "9997     0.0    0.0  ...       0.0  0.210823    0.0   0.0    0.0  0.000000   \n",
       "9998     0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.366276   \n",
       "9999     0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.000000   \n",
       "\n",
       "      write  york      zero  zubrod  \n",
       "0       0.0   0.0  0.000000     0.0  \n",
       "1       0.0   0.0  0.000000     0.0  \n",
       "2       0.0   0.0  0.000000     0.0  \n",
       "3       0.0   0.0  0.099676     0.0  \n",
       "4       0.0   0.0  0.000000     0.0  \n",
       "...     ...   ...       ...     ...  \n",
       "9995    0.0   0.0  0.000000     0.0  \n",
       "9996    0.0   0.0  0.000000     0.0  \n",
       "9997    0.0   0.0  0.000000     0.0  \n",
       "9998    0.0   0.0  0.000000     0.0  \n",
       "9999    0.0   0.0  0.000000     0.0  \n",
       "\n",
       "[10000 rows x 659 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardado del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf('prueba.h5', key = 'clin_trial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('prueba.h5', 'clin_trial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eligible</th>\n",
       "      <th>Interventions</th>\n",
       "      <th>abdomin</th>\n",
       "      <th>abl</th>\n",
       "      <th>abscess</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absorpt</th>\n",
       "      <th>abstin</th>\n",
       "      <th>accord</th>\n",
       "      <th>accur</th>\n",
       "      <th>...</th>\n",
       "      <th>withdraw</th>\n",
       "      <th>within</th>\n",
       "      <th>woman</th>\n",
       "      <th>wort</th>\n",
       "      <th>would</th>\n",
       "      <th>wound</th>\n",
       "      <th>write</th>\n",
       "      <th>york</th>\n",
       "      <th>zero</th>\n",
       "      <th>zubrod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099676</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>1</td>\n",
       "      <td>1109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>1</td>\n",
       "      <td>1201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>1</td>\n",
       "      <td>939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>1</td>\n",
       "      <td>639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 659 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Eligible  Interventions  abdomin  abl  abscess  absolut  absorpt  abstin  \\\n",
       "0           0            464      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "1           0            101      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "2           0            349      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "3           0           1052      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "4           0            708      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "...       ...            ...      ...  ...      ...      ...      ...     ...   \n",
       "9995        1           1109      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "9996        1            200      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "9997        1           1201      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "9998        1            939      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "9999        1            639      0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "\n",
       "      accord  accur  ...  withdraw    within  woman  wort  would     wound  \\\n",
       "0        0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.000000   \n",
       "1        0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.000000   \n",
       "2        0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.000000   \n",
       "3        0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.000000   \n",
       "4        0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.000000   \n",
       "...      ...    ...  ...       ...       ...    ...   ...    ...       ...   \n",
       "9995     0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.000000   \n",
       "9996     0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.000000   \n",
       "9997     0.0    0.0  ...       0.0  0.210823    0.0   0.0    0.0  0.000000   \n",
       "9998     0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.366276   \n",
       "9999     0.0    0.0  ...       0.0  0.000000    0.0   0.0    0.0  0.000000   \n",
       "\n",
       "      write  york      zero  zubrod  \n",
       "0       0.0   0.0  0.000000     0.0  \n",
       "1       0.0   0.0  0.000000     0.0  \n",
       "2       0.0   0.0  0.000000     0.0  \n",
       "3       0.0   0.0  0.099676     0.0  \n",
       "4       0.0   0.0  0.000000     0.0  \n",
       "...     ...   ...       ...     ...  \n",
       "9995    0.0   0.0  0.000000     0.0  \n",
       "9996    0.0   0.0  0.000000     0.0  \n",
       "9997    0.0   0.0  0.000000     0.0  \n",
       "9998    0.0   0.0  0.000000     0.0  \n",
       "9999    0.0   0.0  0.000000     0.0  \n",
       "\n",
       "[10000 rows x 659 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo de selección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler # Escala los datos\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import scikitplot as skplt \n",
    "from string import ascii_uppercase \n",
    "# import seaborn as sns\n",
    "import qgrid\n",
    "import time\n",
    "#from sklearn.externals import joblib # Para guardar el modelo\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "from scipy import stats #Para la moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clin_trial_values = df.values\n",
    "Y = clin_trial_values[:, 0]\n",
    "Y = Y.astype(int)\n",
    "X = clin_trial_values[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_error(y_est, y_real):\n",
    "    err = 0\n",
    "    for y_e, y_r in zip(y_est, y_real):\n",
    "\n",
    "        if y_e != y_r:\n",
    "            err += 1\n",
    "\n",
    "    return err/np.size(y_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(Xtest, Ytest, probs, xlabel):\n",
    "    ns_probs = [0 for _ in range(len(Ytest))]\n",
    "    \n",
    "    probs = probs[:, 1]\n",
    "    ns_auc = roc_auc_score(Ytest, ns_probs)\n",
    "    auc = roc_auc_score(Ytest, probs)  \n",
    "\n",
    "    print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "    print(xlabel, 'ROC AUC=%.3f' % (auc))\n",
    "\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(Ytest, ns_probs)\n",
    "    fpr, tpr, _ = roc_curve(Ytest, probs)   \n",
    "\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "    plt.plot(fpr, tpr, marker='.', label= xlabel)\n",
    "\n",
    "    # axis labels\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler # Escala los datos\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import scikitplot as skplt \n",
    "from string import ascii_uppercase \n",
    "# import seaborn as sns\n",
    "import qgrid\n",
    "import time\n",
    "#from sklearn.externals import joblib # Para guardar el modelo\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_NB(impresion = False):\n",
    "\n",
    "    tiempo_i = time.time()\n",
    "\n",
    "    accuracy_list = np.zeros([4])\n",
    "    precision_list = np.zeros([4,2])\n",
    "    recall_list = np.zeros([4,2])\n",
    "    f_list = np.zeros([4,2]) \n",
    "    errores = np.zeros(4)\n",
    "    nb = GaussianNB()\n",
    "    for j in range(4):\n",
    "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.25) # Modificar metodología de validación\n",
    "        scaler = MinMaxScaler()#Escala entre 0 y 1\n",
    "        Xtrain = scaler.fit_transform(Xtrain)\n",
    "        Xtest = scaler.transform(Xtest)\n",
    "\n",
    "        nb.fit(Xtrain, Ytrain)\n",
    "        pred = nb.predict(Xtest)\n",
    "        \n",
    "        #code for calculating accuracy \n",
    "        _accuracy_ = accuracy_score(Ytest, pred, normalize=True)\n",
    "        accuracy_list[j] = _accuracy_\n",
    "\n",
    "        #code for calculating recall \n",
    "        _recalls_ = recall_score(Ytest, pred, average=None)\n",
    "        recall_list[j] = _recalls_\n",
    "\n",
    "        #code for calculating precision \n",
    "        _precisions_ = precision_score(Ytest, pred, average=None)\n",
    "        precision_list[j] = _precisions_\n",
    "        \n",
    "        _f_score_ = f1_score(Ytest, pred, average=None)\n",
    "        f_list[j] = _f_score_\n",
    "                \n",
    "        errores[j] = classification_error(pred, Ytest)\n",
    "          \n",
    "    if impresion == True:\n",
    "        #Curva ROC\n",
    "        nb_probs = nb.predict_proba(Xtest)\n",
    "        \n",
    "        plot_roc(Xtest, Ytest, nb_probs, \"Naive Bayes\")\n",
    "#         auc = roc_auc_score(Ytest, pred)\n",
    "#         print('AUC: %.2f' % auc)\n",
    "#         fpr, tpr, thresholds = roc_curve(Ytest, pred)\n",
    "#         plot_roc_curve(fpr, tpr)\n",
    "        #Matriz de confusión\n",
    "        skplt.metrics.plot_confusion_matrix(Ytest, pred, normalize=True)\n",
    "\n",
    "    return str(np.mean(accuracy_list)), str(np.std(accuracy_list)), str(np.mean(recall_list)), str(np.std(recall_list)), str(np.mean(precision_list)), str(np.std(precision_list)),  str(np.mean(f_list)), str(np.std(f_list)), str(np.mean(errores)), str(np.std(errores)), str(time.time()-tiempo_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Skill: ROC AUC=0.500\n",
      "Naive Bayes ROC AUC=0.816\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eficiencia 0.7584  Int_Eficiencia 0.009955902771722874  Sensibilidad 0.7586131720141525  Int_Sensibilidad 0.05132252166487334  Precision 0.7610856349041366  Int_Precision 0.02870449557626516  F-Score 0.757838084309258  Int_F-Score 0.015685883375918346  Error_Prueba 0.24159999999999998  Int_Error 0.009955902771722923  Tiempo ejecución 2.404982566833496\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Acc, IntAcc, Sen, IntSen, Pre, IntPre, f, IntF, error, stdError, tiempo = model_NB(impresion = True)\n",
    "print('Eficiencia',Acc, ' Int_Eficiencia', IntAcc,' Sensibilidad', Sen, ' Int_Sensibilidad',IntSen,' Precision', Pre, ' Int_Precision',IntPre,' F-Score', f, ' Int_F-Score',IntF,' Error_Prueba', error,' Int_Error', stdError,' Tiempo ejecución', tiempo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRC(c, slv, impresion = False):\n",
    "\n",
    "    tiempo_i = time.time()\n",
    "    \n",
    "    accuracy_list = np.zeros([4])\n",
    "    precision_list = np.zeros([4,2])\n",
    "    recall_list = np.zeros([4,2])\n",
    "    f_list = np.zeros([4,2]) \n",
    "    errores = np.zeros(4)\n",
    "    LR = LogisticRegression(C=c, solver=slv, max_iter = 200)\n",
    "    for j in range(4):\n",
    "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.25) # Modificar metodología de validación\n",
    "        scaler = MinMaxScaler()#Escala entre 0 y 1\n",
    "        Xtrain = scaler.fit_transform(Xtrain)\n",
    "        Xtest = scaler.transform(Xtest)\n",
    "        \n",
    "        LR.fit(Xtrain, Ytrain)\n",
    "        pred = LR.predict(Xtest)\n",
    "        \n",
    "        #code for calculating accuracy \n",
    "        _accuracy_ = accuracy_score(Ytest, pred, normalize=True)\n",
    "        accuracy_list[j] = _accuracy_\n",
    "\n",
    "        #code for calculating recall \n",
    "        _recalls_ = recall_score(Ytest, pred, average=None)\n",
    "        recall_list[j] = _recalls_\n",
    "\n",
    "        #code for calculating precision \n",
    "        _precisions_ = precision_score(Ytest, pred, average=None)\n",
    "        precision_list[j] = _precisions_\n",
    "        \n",
    "        _f_score_ = f1_score(Ytest, pred, average=None)\n",
    "        f_list[j] = _f_score_\n",
    "\n",
    "                \n",
    "        errores[j] = classification_error(pred, Ytest)\n",
    "           \n",
    "    if impresion == True:\n",
    "        #Curva ROC\n",
    "        \n",
    "        lr_probs = LR.predict_proba(Xtest)\n",
    "        \n",
    "        plot_roc(Xtest, Ytest, lr_probs, \"Logistic Regression\")\n",
    "        \n",
    "#         auc = roc_auc_score(Ytest, pred)\n",
    "#         print('AUC: %.2f' % auc)\n",
    "#         fpr, tpr, thresholds = roc_curve(Ytest, pred)\n",
    "#         plot_roc_curve(fpr, tpr)\n",
    "        #Matriz de confusión\n",
    "        skplt.metrics.plot_confusion_matrix(Ytest, pred, normalize=True)\n",
    "\n",
    "    return str(np.mean(accuracy_list)), str(np.std(accuracy_list)), str(np.mean(recall_list)), str(np.std(recall_list)), str(np.mean(precision_list)), str(np.std(precision_list)),  str(np.mean(f_list)), str(np.std(f_list)), str(np.mean(errores)), str(np.std(errores)), str(time.time()-tiempo_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Skill: ROC AUC=0.500\n",
      "Logistic Regression ROC AUC=0.863\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eficiencia 0.7835  Int_Eficiencia 0.0048363209157375  Sensibilidad 0.783426909130698  Int_Sensibilidad 0.020154406585764367  Precision 0.7838630444592879  Int_Precision 0.01220633912027487  F-Score 0.783357536357792  Int_F-Score 0.007303273979255575  Error_Prueba 0.2165  Int_Error 0.0048363209157375004  Tiempo ejecución 2.0068342685699463\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Acc, IntAcc, Sen, IntSen, Pre, IntPre, f, IntF, error, stdError, tiempo = LRC(1, 'liblinear', impresion = True)\n",
    "print('Eficiencia',Acc, ' Int_Eficiencia', IntAcc,' Sensibilidad', Sen, ' Int_Sensibilidad',IntSen,' Precision', Pre, ' Int_Precision',IntPre,' F-Score', f, ' Int_F-Score',IntF,' Error_Prueba', error,' Int_Error', stdError,' Tiempo ejecución', tiempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dc7192807f4db8acdac35563426388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "#randn = np.random.randn\n",
    "df_types = pd.DataFrame({\n",
    "    'Tipo de solver' : pd.Series(['newton-cg', 'newton-cg', 'newton-cg', 'newton-cg', 'newton-cg', 'newton-cg', \n",
    "                          'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', \n",
    "                          'liblinear', 'liblinear', 'liblinear','liblinear','liblinear','liblinear',\n",
    "                          'sag','sag','sag','sag','sag','sag',\n",
    "                          'saga','saga','saga','saga','saga','saga']),\n",
    "    'Valor de regularización' : pd.Series([0.1,0.5,1,1.5,2,3,\n",
    "                                           0.1,0.5,1,1.5,2,3,\n",
    "                                           0.1,0.5,1,1.5,2,3,\n",
    "                                           0.1,0.5,1,1.5,2,3,\n",
    "                                           0.1,0.5,1,1.5,2,3])})\n",
    "df_types[\"Eficiencia\"] = \"\"\n",
    "df_types[\"Int_Eficiencia\"] = \"\"\n",
    "df_types[\"Sensibilidad\"] = \"\"\n",
    "df_types[\"Int_Sensibilidad\"] = \"\"\n",
    "df_types[\"Precision\"] = \"\"\n",
    "df_types[\"Int_Precision\"] = \"\"\n",
    "df_types[\"F-Score\"] = \"\"\n",
    "df_types[\"Int_F-Score\"] = \"\"\n",
    "df_types[\"Error_Prueba\"] = \"\"\n",
    "df_types[\"Int_error\"] = \"\"\n",
    "df_types[\"Tiempo de ejecución\"] = \"\"\n",
    "df_types.set_index(['Tipo de solver', 'Valor de regularización'], inplace=True)\n",
    "\n",
    "i = 0\n",
    "for k, n in df_types.index:\n",
    "    Acc, IntAcc, Sen, IntSen, Pre, IntPre, f, IntF, error, stdError, tiempo = LRC(n, k, impresion = False)\n",
    "    df_types[\"Eficiencia\"][i] = Acc\n",
    "    df_types[\"Int_Eficiencia\"][i] = IntAcc\n",
    "    df_types[\"Sensibilidad\"][i] = Sen\n",
    "    df_types[\"Int_Sensibilidad\"][i] = IntSen\n",
    "    df_types[\"Precision\"][i] = Pre\n",
    "    df_types[\"Int_Precision\"][i] = IntPre\n",
    "    df_types[\"F-Score\"][i] = f\n",
    "    df_types[\"Int_F-Score\"][i] = IntF\n",
    "    df_types[\"Error_Prueba\"][i] = error\n",
    "    df_types[\"Int_error\"][i] = stdError\n",
    "    df_types[\"Tiempo de ejecución\"][i] = tiempo\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Eficiencia</th>\n",
       "      <th>Int_Eficiencia</th>\n",
       "      <th>Sensibilidad</th>\n",
       "      <th>Int_Sensibilidad</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Int_Precision</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>Int_F-Score</th>\n",
       "      <th>Error_Prueba</th>\n",
       "      <th>Int_error</th>\n",
       "      <th>Tiempo de ejecución</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tipo de solver</th>\n",
       "      <th>Valor de regularización</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"6\" valign=\"top\">newton-cg</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7714</td>\n",
       "      <td>0.004529900661162454</td>\n",
       "      <td>0.7714818751401422</td>\n",
       "      <td>0.016549338980971186</td>\n",
       "      <td>0.7716932660495603</td>\n",
       "      <td>0.011776367137210598</td>\n",
       "      <td>0.7713588507094641</td>\n",
       "      <td>0.005460473755516171</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.0045299006611624545</td>\n",
       "      <td>3.995636224746704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.006343500610861461</td>\n",
       "      <td>0.7820813458850314</td>\n",
       "      <td>0.01270985101736506</td>\n",
       "      <td>0.7821354748561518</td>\n",
       "      <td>0.011266420153329551</td>\n",
       "      <td>0.7819799243445842</td>\n",
       "      <td>0.006678936430888101</td>\n",
       "      <td>0.21800000000000003</td>\n",
       "      <td>0.0063435006108614805</td>\n",
       "      <td>4.149759531021118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7831000000000001</td>\n",
       "      <td>0.00538423625038872</td>\n",
       "      <td>0.7832578871342042</td>\n",
       "      <td>0.023716187723915733</td>\n",
       "      <td>0.7837158157604445</td>\n",
       "      <td>0.017156347512191278</td>\n",
       "      <td>0.7830056924849017</td>\n",
       "      <td>0.006995268184093957</td>\n",
       "      <td>0.21689999999999998</td>\n",
       "      <td>0.005384236250388724</td>\n",
       "      <td>4.60018515586853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.5</td>\n",
       "      <td>0.7816</td>\n",
       "      <td>0.009947864092356703</td>\n",
       "      <td>0.7815631754896086</td>\n",
       "      <td>0.03185835407790194</td>\n",
       "      <td>0.78251885445297</td>\n",
       "      <td>0.020272471468797116</td>\n",
       "      <td>0.7813117077086966</td>\n",
       "      <td>0.012664626383974717</td>\n",
       "      <td>0.21839999999999998</td>\n",
       "      <td>0.009947864092356713</td>\n",
       "      <td>4.8884313106536865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.006790434448545948</td>\n",
       "      <td>0.7863909236834679</td>\n",
       "      <td>0.026022178487659604</td>\n",
       "      <td>0.78711514421889</td>\n",
       "      <td>0.015282291457280519</td>\n",
       "      <td>0.7862887011971729</td>\n",
       "      <td>0.009772195387981662</td>\n",
       "      <td>0.21350000000000002</td>\n",
       "      <td>0.006790434448545987</td>\n",
       "      <td>4.86341667175293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7788999999999999</td>\n",
       "      <td>0.0023216373532487645</td>\n",
       "      <td>0.779148129150383</td>\n",
       "      <td>0.028537653275795945</td>\n",
       "      <td>0.7798698909748283</td>\n",
       "      <td>0.01923719302999681</td>\n",
       "      <td>0.7787847237088206</td>\n",
       "      <td>0.005549588810430615</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.0023216373532487862</td>\n",
       "      <td>5.193715572357178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"6\" valign=\"top\">lbfgs</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7748</td>\n",
       "      <td>0.007076722405181644</td>\n",
       "      <td>0.7749143659760647</td>\n",
       "      <td>0.011990103916849251</td>\n",
       "      <td>0.7748985473605723</td>\n",
       "      <td>0.012239298840928668</td>\n",
       "      <td>0.7747862316916866</td>\n",
       "      <td>0.007273748634269262</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.007076722405181652</td>\n",
       "      <td>2.1799800395965576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7809999999999999</td>\n",
       "      <td>0.008623224454924052</td>\n",
       "      <td>0.7809902991312401</td>\n",
       "      <td>0.020642306881803445</td>\n",
       "      <td>0.7813697037138863</td>\n",
       "      <td>0.014067512678677844</td>\n",
       "      <td>0.7809015818904212</td>\n",
       "      <td>0.009790473047889077</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.008623224454924045</td>\n",
       "      <td>2.5092785358428955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7892</td>\n",
       "      <td>0.007509993342207435</td>\n",
       "      <td>0.789121630216548</td>\n",
       "      <td>0.01472813209226536</td>\n",
       "      <td>0.7893408579394596</td>\n",
       "      <td>0.00993875434647545</td>\n",
       "      <td>0.7891227246936368</td>\n",
       "      <td>0.008449512807870457</td>\n",
       "      <td>0.2108</td>\n",
       "      <td>0.007509993342207435</td>\n",
       "      <td>2.847585678100586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.5</td>\n",
       "      <td>0.7829999999999999</td>\n",
       "      <td>0.007334848328356886</td>\n",
       "      <td>0.7831398340137521</td>\n",
       "      <td>0.020336001941843766</td>\n",
       "      <td>0.7834307815165464</td>\n",
       "      <td>0.015663816434743568</td>\n",
       "      <td>0.782949537886446</td>\n",
       "      <td>0.00803644250090551</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.007334848328356901</td>\n",
       "      <td>3.069282054901123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7751000000000001</td>\n",
       "      <td>0.007463913182774842</td>\n",
       "      <td>0.775052293097156</td>\n",
       "      <td>0.027509110255283</td>\n",
       "      <td>0.7758192775121381</td>\n",
       "      <td>0.015435144201767085</td>\n",
       "      <td>0.7749099093419103</td>\n",
       "      <td>0.010157493529428326</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.007463913182774834</td>\n",
       "      <td>3.258082151412964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7697</td>\n",
       "      <td>0.00442153819388684</td>\n",
       "      <td>0.7698043275751187</td>\n",
       "      <td>0.027954299865347698</td>\n",
       "      <td>0.7705488001638159</td>\n",
       "      <td>0.017042659150692568</td>\n",
       "      <td>0.7695501268696092</td>\n",
       "      <td>0.007395951862323227</td>\n",
       "      <td>0.2303</td>\n",
       "      <td>0.004421538193886831</td>\n",
       "      <td>3.311007261276245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"6\" valign=\"top\">liblinear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7794000000000001</td>\n",
       "      <td>0.003280243893371339</td>\n",
       "      <td>0.7794071173303536</td>\n",
       "      <td>0.01314789148337476</td>\n",
       "      <td>0.7795769639616439</td>\n",
       "      <td>0.008590725794540502</td>\n",
       "      <td>0.7793606744107101</td>\n",
       "      <td>0.004379050254769567</td>\n",
       "      <td>0.22060000000000002</td>\n",
       "      <td>0.00328024389337135</td>\n",
       "      <td>1.8426830768585205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7745</td>\n",
       "      <td>0.006263385665915844</td>\n",
       "      <td>0.7744761922918632</td>\n",
       "      <td>0.01343551710113479</td>\n",
       "      <td>0.7745622127782361</td>\n",
       "      <td>0.010867559447880516</td>\n",
       "      <td>0.7744027666934828</td>\n",
       "      <td>0.007773826118073561</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.006263385665915837</td>\n",
       "      <td>2.1693153381347656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7761</td>\n",
       "      <td>0.0038405728739343177</td>\n",
       "      <td>0.7760769205382884</td>\n",
       "      <td>0.025679910291429443</td>\n",
       "      <td>0.7767032626312621</td>\n",
       "      <td>0.016293369383662385</td>\n",
       "      <td>0.7758716237954123</td>\n",
       "      <td>0.00804378269588291</td>\n",
       "      <td>0.2239</td>\n",
       "      <td>0.003840572873934305</td>\n",
       "      <td>1.9998753070831299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.5</td>\n",
       "      <td>0.7740999999999999</td>\n",
       "      <td>0.006364746656387836</td>\n",
       "      <td>0.7741384788341443</td>\n",
       "      <td>0.019580507641944227</td>\n",
       "      <td>0.7743860777188757</td>\n",
       "      <td>0.015118417147037532</td>\n",
       "      <td>0.7739549163432702</td>\n",
       "      <td>0.008439225571951245</td>\n",
       "      <td>0.22590000000000002</td>\n",
       "      <td>0.0063647466563878236</td>\n",
       "      <td>1.8616907596588135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7759</td>\n",
       "      <td>0.008981647955692734</td>\n",
       "      <td>0.7756671770760196</td>\n",
       "      <td>0.02460780918196396</td>\n",
       "      <td>0.7763299887839632</td>\n",
       "      <td>0.013466309498853645</td>\n",
       "      <td>0.775668334929636</td>\n",
       "      <td>0.01169857858852119</td>\n",
       "      <td>0.22410000000000002</td>\n",
       "      <td>0.008981647955692758</td>\n",
       "      <td>1.863692283630371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7788</td>\n",
       "      <td>0.00609918027279075</td>\n",
       "      <td>0.7789884991147884</td>\n",
       "      <td>0.019730621916749874</td>\n",
       "      <td>0.7792398020201865</td>\n",
       "      <td>0.015101583747589867</td>\n",
       "      <td>0.7787695990900594</td>\n",
       "      <td>0.006660062417286387</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.006099180272790764</td>\n",
       "      <td>1.8780419826507568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"6\" valign=\"top\">sag</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7757000000000001</td>\n",
       "      <td>0.004493328387732204</td>\n",
       "      <td>0.775707883888213</td>\n",
       "      <td>0.01033813171083707</td>\n",
       "      <td>0.7757187103695038</td>\n",
       "      <td>0.009911939296350245</td>\n",
       "      <td>0.775627463592296</td>\n",
       "      <td>0.006005736120677651</td>\n",
       "      <td>0.2243</td>\n",
       "      <td>0.004493328387732197</td>\n",
       "      <td>4.304473876953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7809</td>\n",
       "      <td>0.005588380803059127</td>\n",
       "      <td>0.7812084534925389</td>\n",
       "      <td>0.02258758789582739</td>\n",
       "      <td>0.781495386890377</td>\n",
       "      <td>0.018592130097646403</td>\n",
       "      <td>0.7808649246265764</td>\n",
       "      <td>0.006231052326168734</td>\n",
       "      <td>0.21910000000000002</td>\n",
       "      <td>0.005588380803059148</td>\n",
       "      <td>4.933486461639404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7868999999999999</td>\n",
       "      <td>0.004624932431938835</td>\n",
       "      <td>0.7871026851562097</td>\n",
       "      <td>0.026718940767440212</td>\n",
       "      <td>0.7877302137594816</td>\n",
       "      <td>0.018983245034193505</td>\n",
       "      <td>0.7867986687466678</td>\n",
       "      <td>0.006556370147893332</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.004624932431938876</td>\n",
       "      <td>5.146672964096069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.5</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.0020880613017821327</td>\n",
       "      <td>0.7726353307573259</td>\n",
       "      <td>0.016524758921015504</td>\n",
       "      <td>0.7728098576610961</td>\n",
       "      <td>0.01258908848456467</td>\n",
       "      <td>0.7724829926675428</td>\n",
       "      <td>0.005607182687051781</td>\n",
       "      <td>0.2274</td>\n",
       "      <td>0.0020880613017821067</td>\n",
       "      <td>5.9333884716033936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>0.0024062418831032094</td>\n",
       "      <td>0.7780415252700141</td>\n",
       "      <td>0.019610094199376683</td>\n",
       "      <td>0.7784862156842007</td>\n",
       "      <td>0.010341308278184365</td>\n",
       "      <td>0.7780332094007725</td>\n",
       "      <td>0.008097366485687433</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>0.0024062418831031877</td>\n",
       "      <td>5.4259352684021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7740999999999999</td>\n",
       "      <td>0.003179622619116915</td>\n",
       "      <td>0.7738387047466915</td>\n",
       "      <td>0.020047909617152172</td>\n",
       "      <td>0.7743509363428678</td>\n",
       "      <td>0.008675264260167778</td>\n",
       "      <td>0.7738669257297928</td>\n",
       "      <td>0.00790911113168984</td>\n",
       "      <td>0.2259</td>\n",
       "      <td>0.003179622619116936</td>\n",
       "      <td>5.813270568847656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"6\" valign=\"top\">saga</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7696</td>\n",
       "      <td>0.006368673331236235</td>\n",
       "      <td>0.7697251703720754</td>\n",
       "      <td>0.0110969019058563</td>\n",
       "      <td>0.7696446253934005</td>\n",
       "      <td>0.013124458622336637</td>\n",
       "      <td>0.7695567223479635</td>\n",
       "      <td>0.007083948640639065</td>\n",
       "      <td>0.2304</td>\n",
       "      <td>0.0063686733312362685</td>\n",
       "      <td>4.541517019271851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7828999999999999</td>\n",
       "      <td>0.005443344560102709</td>\n",
       "      <td>0.7831533858314086</td>\n",
       "      <td>0.0173900898367545</td>\n",
       "      <td>0.7831870085026311</td>\n",
       "      <td>0.01672031958793615</td>\n",
       "      <td>0.782852470706466</td>\n",
       "      <td>0.006350214474958596</td>\n",
       "      <td>0.21710000000000002</td>\n",
       "      <td>0.005443344560102735</td>\n",
       "      <td>4.806934356689453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7764</td>\n",
       "      <td>0.004399999999999982</td>\n",
       "      <td>0.7766938752107998</td>\n",
       "      <td>0.02709508709368196</td>\n",
       "      <td>0.777283341041523</td>\n",
       "      <td>0.01926830943521423</td>\n",
       "      <td>0.7763253778691754</td>\n",
       "      <td>0.005995622410353862</td>\n",
       "      <td>0.2236</td>\n",
       "      <td>0.004399999999999998</td>\n",
       "      <td>6.4089977741241455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.5</td>\n",
       "      <td>0.7736000000000001</td>\n",
       "      <td>0.0035665109000254038</td>\n",
       "      <td>0.7739344524198379</td>\n",
       "      <td>0.027843704800715</td>\n",
       "      <td>0.7745309204356762</td>\n",
       "      <td>0.019987520679557152</td>\n",
       "      <td>0.7735130269361561</td>\n",
       "      <td>0.005679559559819741</td>\n",
       "      <td>0.22640000000000002</td>\n",
       "      <td>0.003566510900025405</td>\n",
       "      <td>8.518311977386475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7796</td>\n",
       "      <td>0.014458215657542276</td>\n",
       "      <td>0.7796227230673825</td>\n",
       "      <td>0.02512744266469657</td>\n",
       "      <td>0.7800276802079376</td>\n",
       "      <td>0.019185521255460383</td>\n",
       "      <td>0.7794824842244202</td>\n",
       "      <td>0.015364792623452932</td>\n",
       "      <td>0.22039999999999998</td>\n",
       "      <td>0.014458215657542252</td>\n",
       "      <td>8.981491327285767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7835</td>\n",
       "      <td>0.010504760825454347</td>\n",
       "      <td>0.783522130411096</td>\n",
       "      <td>0.020501844071543512</td>\n",
       "      <td>0.7838286247411217</td>\n",
       "      <td>0.014917744992316228</td>\n",
       "      <td>0.7834255340415763</td>\n",
       "      <td>0.011347539969626</td>\n",
       "      <td>0.21649999999999997</td>\n",
       "      <td>0.010504760825454328</td>\n",
       "      <td>12.50889778137207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Eficiencia  \\\n",
       "Tipo de solver Valor de regularización                       \n",
       "newton-cg      0.1                                  0.7714   \n",
       "               0.5                                   0.782   \n",
       "               1.0                      0.7831000000000001   \n",
       "               1.5                                  0.7816   \n",
       "               2.0                                  0.7865   \n",
       "               3.0                      0.7788999999999999   \n",
       "lbfgs          0.1                                  0.7748   \n",
       "               0.5                      0.7809999999999999   \n",
       "               1.0                                  0.7892   \n",
       "               1.5                      0.7829999999999999   \n",
       "               2.0                      0.7751000000000001   \n",
       "               3.0                                  0.7697   \n",
       "liblinear      0.1                      0.7794000000000001   \n",
       "               0.5                                  0.7745   \n",
       "               1.0                                  0.7761   \n",
       "               1.5                      0.7740999999999999   \n",
       "               2.0                                  0.7759   \n",
       "               3.0                                  0.7788   \n",
       "sag            0.1                      0.7757000000000001   \n",
       "               0.5                                  0.7809   \n",
       "               1.0                      0.7868999999999999   \n",
       "               1.5                                  0.7726   \n",
       "               2.0                                  0.7783   \n",
       "               3.0                      0.7740999999999999   \n",
       "saga           0.1                                  0.7696   \n",
       "               0.5                      0.7828999999999999   \n",
       "               1.0                                  0.7764   \n",
       "               1.5                      0.7736000000000001   \n",
       "               2.0                                  0.7796   \n",
       "               3.0                                  0.7835   \n",
       "\n",
       "                                               Int_Eficiencia  \\\n",
       "Tipo de solver Valor de regularización                          \n",
       "newton-cg      0.1                       0.004529900661162454   \n",
       "               0.5                       0.006343500610861461   \n",
       "               1.0                        0.00538423625038872   \n",
       "               1.5                       0.009947864092356703   \n",
       "               2.0                       0.006790434448545948   \n",
       "               3.0                      0.0023216373532487645   \n",
       "lbfgs          0.1                       0.007076722405181644   \n",
       "               0.5                       0.008623224454924052   \n",
       "               1.0                       0.007509993342207435   \n",
       "               1.5                       0.007334848328356886   \n",
       "               2.0                       0.007463913182774842   \n",
       "               3.0                        0.00442153819388684   \n",
       "liblinear      0.1                       0.003280243893371339   \n",
       "               0.5                       0.006263385665915844   \n",
       "               1.0                      0.0038405728739343177   \n",
       "               1.5                       0.006364746656387836   \n",
       "               2.0                       0.008981647955692734   \n",
       "               3.0                        0.00609918027279075   \n",
       "sag            0.1                       0.004493328387732204   \n",
       "               0.5                       0.005588380803059127   \n",
       "               1.0                       0.004624932431938835   \n",
       "               1.5                      0.0020880613017821327   \n",
       "               2.0                      0.0024062418831032094   \n",
       "               3.0                       0.003179622619116915   \n",
       "saga           0.1                       0.006368673331236235   \n",
       "               0.5                       0.005443344560102709   \n",
       "               1.0                       0.004399999999999982   \n",
       "               1.5                      0.0035665109000254038   \n",
       "               2.0                       0.014458215657542276   \n",
       "               3.0                       0.010504760825454347   \n",
       "\n",
       "                                              Sensibilidad  \\\n",
       "Tipo de solver Valor de regularización                       \n",
       "newton-cg      0.1                      0.7714818751401422   \n",
       "               0.5                      0.7820813458850314   \n",
       "               1.0                      0.7832578871342042   \n",
       "               1.5                      0.7815631754896086   \n",
       "               2.0                      0.7863909236834679   \n",
       "               3.0                       0.779148129150383   \n",
       "lbfgs          0.1                      0.7749143659760647   \n",
       "               0.5                      0.7809902991312401   \n",
       "               1.0                       0.789121630216548   \n",
       "               1.5                      0.7831398340137521   \n",
       "               2.0                       0.775052293097156   \n",
       "               3.0                      0.7698043275751187   \n",
       "liblinear      0.1                      0.7794071173303536   \n",
       "               0.5                      0.7744761922918632   \n",
       "               1.0                      0.7760769205382884   \n",
       "               1.5                      0.7741384788341443   \n",
       "               2.0                      0.7756671770760196   \n",
       "               3.0                      0.7789884991147884   \n",
       "sag            0.1                       0.775707883888213   \n",
       "               0.5                      0.7812084534925389   \n",
       "               1.0                      0.7871026851562097   \n",
       "               1.5                      0.7726353307573259   \n",
       "               2.0                      0.7780415252700141   \n",
       "               3.0                      0.7738387047466915   \n",
       "saga           0.1                      0.7697251703720754   \n",
       "               0.5                      0.7831533858314086   \n",
       "               1.0                      0.7766938752107998   \n",
       "               1.5                      0.7739344524198379   \n",
       "               2.0                      0.7796227230673825   \n",
       "               3.0                       0.783522130411096   \n",
       "\n",
       "                                            Int_Sensibilidad  \\\n",
       "Tipo de solver Valor de regularización                         \n",
       "newton-cg      0.1                      0.016549338980971186   \n",
       "               0.5                       0.01270985101736506   \n",
       "               1.0                      0.023716187723915733   \n",
       "               1.5                       0.03185835407790194   \n",
       "               2.0                      0.026022178487659604   \n",
       "               3.0                      0.028537653275795945   \n",
       "lbfgs          0.1                      0.011990103916849251   \n",
       "               0.5                      0.020642306881803445   \n",
       "               1.0                       0.01472813209226536   \n",
       "               1.5                      0.020336001941843766   \n",
       "               2.0                         0.027509110255283   \n",
       "               3.0                      0.027954299865347698   \n",
       "liblinear      0.1                       0.01314789148337476   \n",
       "               0.5                       0.01343551710113479   \n",
       "               1.0                      0.025679910291429443   \n",
       "               1.5                      0.019580507641944227   \n",
       "               2.0                       0.02460780918196396   \n",
       "               3.0                      0.019730621916749874   \n",
       "sag            0.1                       0.01033813171083707   \n",
       "               0.5                       0.02258758789582739   \n",
       "               1.0                      0.026718940767440212   \n",
       "               1.5                      0.016524758921015504   \n",
       "               2.0                      0.019610094199376683   \n",
       "               3.0                      0.020047909617152172   \n",
       "saga           0.1                        0.0110969019058563   \n",
       "               0.5                        0.0173900898367545   \n",
       "               1.0                       0.02709508709368196   \n",
       "               1.5                         0.027843704800715   \n",
       "               2.0                       0.02512744266469657   \n",
       "               3.0                      0.020501844071543512   \n",
       "\n",
       "                                                 Precision  \\\n",
       "Tipo de solver Valor de regularización                       \n",
       "newton-cg      0.1                      0.7716932660495603   \n",
       "               0.5                      0.7821354748561518   \n",
       "               1.0                      0.7837158157604445   \n",
       "               1.5                        0.78251885445297   \n",
       "               2.0                        0.78711514421889   \n",
       "               3.0                      0.7798698909748283   \n",
       "lbfgs          0.1                      0.7748985473605723   \n",
       "               0.5                      0.7813697037138863   \n",
       "               1.0                      0.7893408579394596   \n",
       "               1.5                      0.7834307815165464   \n",
       "               2.0                      0.7758192775121381   \n",
       "               3.0                      0.7705488001638159   \n",
       "liblinear      0.1                      0.7795769639616439   \n",
       "               0.5                      0.7745622127782361   \n",
       "               1.0                      0.7767032626312621   \n",
       "               1.5                      0.7743860777188757   \n",
       "               2.0                      0.7763299887839632   \n",
       "               3.0                      0.7792398020201865   \n",
       "sag            0.1                      0.7757187103695038   \n",
       "               0.5                       0.781495386890377   \n",
       "               1.0                      0.7877302137594816   \n",
       "               1.5                      0.7728098576610961   \n",
       "               2.0                      0.7784862156842007   \n",
       "               3.0                      0.7743509363428678   \n",
       "saga           0.1                      0.7696446253934005   \n",
       "               0.5                      0.7831870085026311   \n",
       "               1.0                       0.777283341041523   \n",
       "               1.5                      0.7745309204356762   \n",
       "               2.0                      0.7800276802079376   \n",
       "               3.0                      0.7838286247411217   \n",
       "\n",
       "                                               Int_Precision  \\\n",
       "Tipo de solver Valor de regularización                         \n",
       "newton-cg      0.1                      0.011776367137210598   \n",
       "               0.5                      0.011266420153329551   \n",
       "               1.0                      0.017156347512191278   \n",
       "               1.5                      0.020272471468797116   \n",
       "               2.0                      0.015282291457280519   \n",
       "               3.0                       0.01923719302999681   \n",
       "lbfgs          0.1                      0.012239298840928668   \n",
       "               0.5                      0.014067512678677844   \n",
       "               1.0                       0.00993875434647545   \n",
       "               1.5                      0.015663816434743568   \n",
       "               2.0                      0.015435144201767085   \n",
       "               3.0                      0.017042659150692568   \n",
       "liblinear      0.1                      0.008590725794540502   \n",
       "               0.5                      0.010867559447880516   \n",
       "               1.0                      0.016293369383662385   \n",
       "               1.5                      0.015118417147037532   \n",
       "               2.0                      0.013466309498853645   \n",
       "               3.0                      0.015101583747589867   \n",
       "sag            0.1                      0.009911939296350245   \n",
       "               0.5                      0.018592130097646403   \n",
       "               1.0                      0.018983245034193505   \n",
       "               1.5                       0.01258908848456467   \n",
       "               2.0                      0.010341308278184365   \n",
       "               3.0                      0.008675264260167778   \n",
       "saga           0.1                      0.013124458622336637   \n",
       "               0.5                       0.01672031958793615   \n",
       "               1.0                       0.01926830943521423   \n",
       "               1.5                      0.019987520679557152   \n",
       "               2.0                      0.019185521255460383   \n",
       "               3.0                      0.014917744992316228   \n",
       "\n",
       "                                                   F-Score  \\\n",
       "Tipo de solver Valor de regularización                       \n",
       "newton-cg      0.1                      0.7713588507094641   \n",
       "               0.5                      0.7819799243445842   \n",
       "               1.0                      0.7830056924849017   \n",
       "               1.5                      0.7813117077086966   \n",
       "               2.0                      0.7862887011971729   \n",
       "               3.0                      0.7787847237088206   \n",
       "lbfgs          0.1                      0.7747862316916866   \n",
       "               0.5                      0.7809015818904212   \n",
       "               1.0                      0.7891227246936368   \n",
       "               1.5                       0.782949537886446   \n",
       "               2.0                      0.7749099093419103   \n",
       "               3.0                      0.7695501268696092   \n",
       "liblinear      0.1                      0.7793606744107101   \n",
       "               0.5                      0.7744027666934828   \n",
       "               1.0                      0.7758716237954123   \n",
       "               1.5                      0.7739549163432702   \n",
       "               2.0                       0.775668334929636   \n",
       "               3.0                      0.7787695990900594   \n",
       "sag            0.1                       0.775627463592296   \n",
       "               0.5                      0.7808649246265764   \n",
       "               1.0                      0.7867986687466678   \n",
       "               1.5                      0.7724829926675428   \n",
       "               2.0                      0.7780332094007725   \n",
       "               3.0                      0.7738669257297928   \n",
       "saga           0.1                      0.7695567223479635   \n",
       "               0.5                       0.782852470706466   \n",
       "               1.0                      0.7763253778691754   \n",
       "               1.5                      0.7735130269361561   \n",
       "               2.0                      0.7794824842244202   \n",
       "               3.0                      0.7834255340415763   \n",
       "\n",
       "                                                 Int_F-Score  \\\n",
       "Tipo de solver Valor de regularización                         \n",
       "newton-cg      0.1                      0.005460473755516171   \n",
       "               0.5                      0.006678936430888101   \n",
       "               1.0                      0.006995268184093957   \n",
       "               1.5                      0.012664626383974717   \n",
       "               2.0                      0.009772195387981662   \n",
       "               3.0                      0.005549588810430615   \n",
       "lbfgs          0.1                      0.007273748634269262   \n",
       "               0.5                      0.009790473047889077   \n",
       "               1.0                      0.008449512807870457   \n",
       "               1.5                       0.00803644250090551   \n",
       "               2.0                      0.010157493529428326   \n",
       "               3.0                      0.007395951862323227   \n",
       "liblinear      0.1                      0.004379050254769567   \n",
       "               0.5                      0.007773826118073561   \n",
       "               1.0                       0.00804378269588291   \n",
       "               1.5                      0.008439225571951245   \n",
       "               2.0                       0.01169857858852119   \n",
       "               3.0                      0.006660062417286387   \n",
       "sag            0.1                      0.006005736120677651   \n",
       "               0.5                      0.006231052326168734   \n",
       "               1.0                      0.006556370147893332   \n",
       "               1.5                      0.005607182687051781   \n",
       "               2.0                      0.008097366485687433   \n",
       "               3.0                       0.00790911113168984   \n",
       "saga           0.1                      0.007083948640639065   \n",
       "               0.5                      0.006350214474958596   \n",
       "               1.0                      0.005995622410353862   \n",
       "               1.5                      0.005679559559819741   \n",
       "               2.0                      0.015364792623452932   \n",
       "               3.0                         0.011347539969626   \n",
       "\n",
       "                                               Error_Prueba  \\\n",
       "Tipo de solver Valor de regularización                        \n",
       "newton-cg      0.1                                   0.2286   \n",
       "               0.5                      0.21800000000000003   \n",
       "               1.0                      0.21689999999999998   \n",
       "               1.5                      0.21839999999999998   \n",
       "               2.0                      0.21350000000000002   \n",
       "               3.0                                   0.2211   \n",
       "lbfgs          0.1                                   0.2252   \n",
       "               0.5                                    0.219   \n",
       "               1.0                                   0.2108   \n",
       "               1.5                                    0.217   \n",
       "               2.0                                   0.2249   \n",
       "               3.0                                   0.2303   \n",
       "liblinear      0.1                      0.22060000000000002   \n",
       "               0.5                                   0.2255   \n",
       "               1.0                                   0.2239   \n",
       "               1.5                      0.22590000000000002   \n",
       "               2.0                      0.22410000000000002   \n",
       "               3.0                                   0.2212   \n",
       "sag            0.1                                   0.2243   \n",
       "               0.5                      0.21910000000000002   \n",
       "               1.0                                   0.2131   \n",
       "               1.5                                   0.2274   \n",
       "               2.0                                   0.2217   \n",
       "               3.0                                   0.2259   \n",
       "saga           0.1                                   0.2304   \n",
       "               0.5                      0.21710000000000002   \n",
       "               1.0                                   0.2236   \n",
       "               1.5                      0.22640000000000002   \n",
       "               2.0                      0.22039999999999998   \n",
       "               3.0                      0.21649999999999997   \n",
       "\n",
       "                                                    Int_error  \\\n",
       "Tipo de solver Valor de regularización                          \n",
       "newton-cg      0.1                      0.0045299006611624545   \n",
       "               0.5                      0.0063435006108614805   \n",
       "               1.0                       0.005384236250388724   \n",
       "               1.5                       0.009947864092356713   \n",
       "               2.0                       0.006790434448545987   \n",
       "               3.0                      0.0023216373532487862   \n",
       "lbfgs          0.1                       0.007076722405181652   \n",
       "               0.5                       0.008623224454924045   \n",
       "               1.0                       0.007509993342207435   \n",
       "               1.5                       0.007334848328356901   \n",
       "               2.0                       0.007463913182774834   \n",
       "               3.0                       0.004421538193886831   \n",
       "liblinear      0.1                        0.00328024389337135   \n",
       "               0.5                       0.006263385665915837   \n",
       "               1.0                       0.003840572873934305   \n",
       "               1.5                      0.0063647466563878236   \n",
       "               2.0                       0.008981647955692758   \n",
       "               3.0                       0.006099180272790764   \n",
       "sag            0.1                       0.004493328387732197   \n",
       "               0.5                       0.005588380803059148   \n",
       "               1.0                       0.004624932431938876   \n",
       "               1.5                      0.0020880613017821067   \n",
       "               2.0                      0.0024062418831031877   \n",
       "               3.0                       0.003179622619116936   \n",
       "saga           0.1                      0.0063686733312362685   \n",
       "               0.5                       0.005443344560102735   \n",
       "               1.0                       0.004399999999999998   \n",
       "               1.5                       0.003566510900025405   \n",
       "               2.0                       0.014458215657542252   \n",
       "               3.0                       0.010504760825454328   \n",
       "\n",
       "                                       Tiempo de ejecución  \n",
       "Tipo de solver Valor de regularización                      \n",
       "newton-cg      0.1                       3.995636224746704  \n",
       "               0.5                       4.149759531021118  \n",
       "               1.0                        4.60018515586853  \n",
       "               1.5                      4.8884313106536865  \n",
       "               2.0                        4.86341667175293  \n",
       "               3.0                       5.193715572357178  \n",
       "lbfgs          0.1                      2.1799800395965576  \n",
       "               0.5                      2.5092785358428955  \n",
       "               1.0                       2.847585678100586  \n",
       "               1.5                       3.069282054901123  \n",
       "               2.0                       3.258082151412964  \n",
       "               3.0                       3.311007261276245  \n",
       "liblinear      0.1                      1.8426830768585205  \n",
       "               0.5                      2.1693153381347656  \n",
       "               1.0                      1.9998753070831299  \n",
       "               1.5                      1.8616907596588135  \n",
       "               2.0                       1.863692283630371  \n",
       "               3.0                      1.8780419826507568  \n",
       "sag            0.1                       4.304473876953125  \n",
       "               0.5                       4.933486461639404  \n",
       "               1.0                       5.146672964096069  \n",
       "               1.5                      5.9333884716033936  \n",
       "               2.0                         5.4259352684021  \n",
       "               3.0                       5.813270568847656  \n",
       "saga           0.1                       4.541517019271851  \n",
       "               0.5                       4.806934356689453  \n",
       "               1.0                      6.4089977741241455  \n",
       "               1.5                       8.518311977386475  \n",
       "               2.0                       8.981491327285767  \n",
       "               3.0                       12.50889778137207  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # Se llama a la librería del método Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_RF(estimadores, caracteristicas, impresion = False):\n",
    "        \n",
    "    tiempo_i = time.time()\n",
    "    \n",
    "    accuracy_list = np.zeros([4])\n",
    "    precision_list = np.zeros([4,2])\n",
    "    recall_list = np.zeros([4,2])\n",
    "    f_list = np.zeros([4,2]) \n",
    "    errores = np.zeros(4)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=estimadores, max_features =caracteristicas, n_jobs = -1)\n",
    "    \n",
    "    for j in range(4):\n",
    "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.25) # Modificar metodología de validación\n",
    "        scaler = MinMaxScaler()#Escala entre 0 y 1\n",
    "        Xtrain = scaler.fit_transform(Xtrain)\n",
    "        Xtest = scaler.transform(Xtest)\n",
    "        \n",
    "        RF.fit(Xtrain, Ytrain)\n",
    "        pred = RF.predict(Xtest)\n",
    "        \n",
    "        #code for calculating accuracy \n",
    "        _accuracy_ = accuracy_score(Ytest, pred, normalize=True)\n",
    "        accuracy_list[j] = _accuracy_\n",
    "\n",
    "        #code for calculating recall \n",
    "        _recalls_ = recall_score(Ytest, pred, average=None)\n",
    "        recall_list[j] = _recalls_\n",
    "\n",
    "        #code for calculating precision \n",
    "        _precisions_ = precision_score(Ytest, pred, average=None)\n",
    "        precision_list[j] = _precisions_\n",
    "        \n",
    "        _f_score_ = f1_score(Ytest, pred, average=None)\n",
    "        f_list[j] = _f_score_\n",
    "\n",
    "        \n",
    "        errores[j] = classification_error(pred, Ytest)\n",
    "       \n",
    "    \n",
    "    if impresion == True:\n",
    "        #Curva ROC\n",
    "        \n",
    "        rf_probs = RF.predict_proba(Xtest)\n",
    "        \n",
    "        plot_roc(Xtest, Ytest, rf_probs, \"Random Forest\")\n",
    "#         auc = roc_auc_score(Ytest, pred)\n",
    "#         print('AUC: %.2f' % auc)\n",
    "#         fpr, tpr, thresholds = roc_curve(Ytest, pred)\n",
    "#         plot_roc_curve(fpr, tpr)\n",
    "        #Matriz de confusión\n",
    "        skplt.metrics.plot_confusion_matrix(Ytest, pred, normalize=True)\n",
    "\n",
    "    return str(np.mean(accuracy_list)), str(np.std(accuracy_list)), str(np.mean(recall_list)), str(np.std(recall_list)), str(np.mean(precision_list)), str(np.std(precision_list)),  str(np.mean(f_list)), str(np.std(f_list)), str(np.mean(errores)), str(np.std(errores)), str(time.time()-tiempo_i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-b90c685f4771>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIntAcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIntSen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIntPre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIntF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtiempo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimpresion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Eficiencia'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' Int_Eficiencia'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIntAcc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' Sensibilidad'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' Int_Sensibilidad'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mIntSen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' Precision'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' Int_Precision'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mIntPre\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' F-Score'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' Int_F-Score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mIntF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' Error_Prueba'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' Int_Error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdError\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' Tiempo ejecución'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtiempo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RF' is not defined"
     ]
    }
   ],
   "source": [
    "Acc, IntAcc, Sen, IntSen, Pre, IntPre, f, IntF, error, stdError, tiempo = RF(100, 5, impresion = True)\n",
    "print('Eficiencia',Acc, ' Int_Eficiencia', IntAcc,' Sensibilidad', Sen, ' Int_Sensibilidad',IntSen,' Precision', Pre, ' Int_Precision',IntPre,' F-Score', f, ' Int_F-Score',IntF,' Error_Prueba', error,' Int_Error', stdError,' Tiempo ejecución', tiempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d042ba73644ac69e7a9a5c06e0247e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "randn = np.random.randn\n",
    "df_types = pd.DataFrame({\n",
    "    'Numero de arboles' : pd.Series([5,5,5,5,5,5,5,\n",
    "                                     10,10,10,10,10,10,10,\n",
    "                                     20,20,20,20,20,20,20,\n",
    "                                     50,50,50,50,50,50,50,\n",
    "                                     100,100,100,100,100,100,100]), \n",
    "    'Variables analizadas por nodo' : pd.Series([10,50,100,200,250,350,500,\n",
    "                                                 10,50,100,200,250,350,500,\n",
    "                                                 10,50,100,200,250,350,500,\n",
    "                                                 10,50,100,200,250,350,500,\n",
    "                                                 10,50,100,200,250,350,500])})\n",
    "df_types[\"Eficiencia\"] = \"\"\n",
    "df_types[\"Int_Eficiencia\"] = \"\"\n",
    "df_types[\"Sensibilidad\"] = \"\"\n",
    "df_types[\"Int_Sensibilidad\"] = \"\"\n",
    "df_types[\"Precision\"] = \"\"\n",
    "df_types[\"Int_Precision\"] = \"\"\n",
    "df_types[\"F-Score\"] = \"\"\n",
    "df_types[\"Int_F-Score\"] = \"\"\n",
    "df_types[\"Error_Prueba\"] = \"\"\n",
    "df_types[\"Int_error\"] = \"\"\n",
    "df_types[\"Tiempo de ejecución\"] = \"\"\n",
    "df_types.set_index(['Numero de arboles','Variables analizadas por nodo'], inplace=True)\n",
    "\n",
    "for n, k in df_types.index:\n",
    "    Acc, IntAcc, Sen, IntSen, Pre, IntPre, f, IntF, error, stdError, tiempo = model_RF(n, k, impresion = False)\n",
    "    df_types[\"Eficiencia\"][n,k] = Acc\n",
    "    df_types[\"Int_Eficiencia\"][n,k] = IntAcc\n",
    "    df_types[\"Sensibilidad\"][n,k] = Sen\n",
    "    df_types[\"Int_Sensibilidad\"][n,k] = IntSen\n",
    "    df_types[\"Precision\"][n,k] = Pre\n",
    "    df_types[\"Int_Precision\"][n,k] = IntPre\n",
    "    df_types[\"F-Score\"][n,k] = f\n",
    "    df_types[\"Int_F-Score\"][n,k] = IntF\n",
    "    df_types[\"Error_Prueba\"][n,k] = error\n",
    "    df_types[\"Int_error\"][n,k] = stdError\n",
    "    df_types[\"Tiempo de ejecución\"][n,k] = tiempo\n",
    "\n",
    "\n",
    "#df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Eficiencia</th>\n",
       "      <th>Int_Eficiencia</th>\n",
       "      <th>Sensibilidad</th>\n",
       "      <th>Int_Sensibilidad</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Int_Precision</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>Int_F-Score</th>\n",
       "      <th>Error_Prueba</th>\n",
       "      <th>Int_error</th>\n",
       "      <th>Tiempo de ejecución</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Numero de arboles</th>\n",
       "      <th>Variables analizadas por nodo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"7\" valign=\"top\">5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.007720103626247511</td>\n",
       "      <td>0.7681197522306458</td>\n",
       "      <td>0.01562978505869847</td>\n",
       "      <td>0.7681596542808651</td>\n",
       "      <td>0.014574833875643789</td>\n",
       "      <td>0.7679411688287637</td>\n",
       "      <td>0.008585429324470489</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.007720103626247512</td>\n",
       "      <td>2.736989736557007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>0.005094114250779986</td>\n",
       "      <td>0.7527230379895022</td>\n",
       "      <td>0.01465903924467677</td>\n",
       "      <td>0.7527088689318898</td>\n",
       "      <td>0.015211762848628898</td>\n",
       "      <td>0.7524621824742599</td>\n",
       "      <td>0.005887323185144872</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.005094114250780005</td>\n",
       "      <td>3.2297675609588623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.7513999999999998</td>\n",
       "      <td>0.00980408078302091</td>\n",
       "      <td>0.7517487781704586</td>\n",
       "      <td>0.021133867588757342</td>\n",
       "      <td>0.7518335029234671</td>\n",
       "      <td>0.01966142703793593</td>\n",
       "      <td>0.7513772834842649</td>\n",
       "      <td>0.01011591448388318</td>\n",
       "      <td>0.2486</td>\n",
       "      <td>0.009804080783020919</td>\n",
       "      <td>4.223835468292236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.7476</td>\n",
       "      <td>0.008527602242131145</td>\n",
       "      <td>0.747646256213125</td>\n",
       "      <td>0.013888268288366612</td>\n",
       "      <td>0.7477293905545236</td>\n",
       "      <td>0.011411926364915058</td>\n",
       "      <td>0.7475769457935577</td>\n",
       "      <td>0.008844526065819895</td>\n",
       "      <td>0.25239999999999996</td>\n",
       "      <td>0.008527602242131135</td>\n",
       "      <td>5.480790138244629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.7521</td>\n",
       "      <td>0.00986458311334037</td>\n",
       "      <td>0.75217275997439</td>\n",
       "      <td>0.02173734488995919</td>\n",
       "      <td>0.7524474062046478</td>\n",
       "      <td>0.016854080654819168</td>\n",
       "      <td>0.7519870084943077</td>\n",
       "      <td>0.011224627950828632</td>\n",
       "      <td>0.2479</td>\n",
       "      <td>0.009864583113340375</td>\n",
       "      <td>5.72574520111084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.00567450438364446</td>\n",
       "      <td>0.7529202636888145</td>\n",
       "      <td>0.01337853231848005</td>\n",
       "      <td>0.7530517645337671</td>\n",
       "      <td>0.008917174000705545</td>\n",
       "      <td>0.7528922910437856</td>\n",
       "      <td>0.007735303630441002</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.00567450438364444</td>\n",
       "      <td>6.676495552062988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.7571000000000001</td>\n",
       "      <td>0.005867708240872232</td>\n",
       "      <td>0.7573328054986118</td>\n",
       "      <td>0.015199643787813905</td>\n",
       "      <td>0.7573130975779225</td>\n",
       "      <td>0.01586270908163376</td>\n",
       "      <td>0.7570625985865006</td>\n",
       "      <td>0.006581461074606912</td>\n",
       "      <td>0.2429</td>\n",
       "      <td>0.005867708240872241</td>\n",
       "      <td>6.355423450469971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"7\" valign=\"top\">10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7814</td>\n",
       "      <td>0.00819999999999999</td>\n",
       "      <td>0.7811151267245141</td>\n",
       "      <td>0.023098747024502226</td>\n",
       "      <td>0.7817450462702595</td>\n",
       "      <td>0.012311369628205665</td>\n",
       "      <td>0.7811502951516653</td>\n",
       "      <td>0.011117979255308285</td>\n",
       "      <td>0.2186</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>2.811055898666382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.7699</td>\n",
       "      <td>0.003923009049186621</td>\n",
       "      <td>0.7700826063454782</td>\n",
       "      <td>0.013380693239213183</td>\n",
       "      <td>0.769929780546923</td>\n",
       "      <td>0.016727362234699835</td>\n",
       "      <td>0.7697670783783414</td>\n",
       "      <td>0.006777102427305084</td>\n",
       "      <td>0.23010000000000003</td>\n",
       "      <td>0.003923009049186607</td>\n",
       "      <td>3.5221989154815674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.7666000000000001</td>\n",
       "      <td>0.006636264009214825</td>\n",
       "      <td>0.766612027848639</td>\n",
       "      <td>0.009765084156212465</td>\n",
       "      <td>0.7666447204504659</td>\n",
       "      <td>0.00838794960707761</td>\n",
       "      <td>0.7665825727163263</td>\n",
       "      <td>0.006953935089289847</td>\n",
       "      <td>0.23340000000000002</td>\n",
       "      <td>0.00663626400921482</td>\n",
       "      <td>4.026188611984253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.7644</td>\n",
       "      <td>0.01107429455992571</td>\n",
       "      <td>0.7644767727277894</td>\n",
       "      <td>0.016308392524102815</td>\n",
       "      <td>0.764534228641272</td>\n",
       "      <td>0.015162802744504595</td>\n",
       "      <td>0.7643534669970106</td>\n",
       "      <td>0.011580764035632633</td>\n",
       "      <td>0.23559999999999998</td>\n",
       "      <td>0.011074294559925703</td>\n",
       "      <td>5.784253120422363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.002849561369754992</td>\n",
       "      <td>0.7630091590720154</td>\n",
       "      <td>0.013230783291164994</td>\n",
       "      <td>0.7631271495858591</td>\n",
       "      <td>0.009693778024068123</td>\n",
       "      <td>0.7629241131588711</td>\n",
       "      <td>0.005071631032582017</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.0028495613697549944</td>\n",
       "      <td>6.1896209716796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.7581</td>\n",
       "      <td>0.002762245463386639</td>\n",
       "      <td>0.7580381894170327</td>\n",
       "      <td>0.006355449240014822</td>\n",
       "      <td>0.7580451209602892</td>\n",
       "      <td>0.006029379603136729</td>\n",
       "      <td>0.7580245888116479</td>\n",
       "      <td>0.00503602335595156</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.002762245463386627</td>\n",
       "      <td>7.629929304122925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.7652</td>\n",
       "      <td>0.008611620056644405</td>\n",
       "      <td>0.7652475017315867</td>\n",
       "      <td>0.01502266030435888</td>\n",
       "      <td>0.7653437422369807</td>\n",
       "      <td>0.0122889624633625</td>\n",
       "      <td>0.7651559919002772</td>\n",
       "      <td>0.0091950486287082</td>\n",
       "      <td>0.2348</td>\n",
       "      <td>0.00861162005664439</td>\n",
       "      <td>9.305449962615967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"7\" valign=\"top\">20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7821</td>\n",
       "      <td>0.0021610182784974332</td>\n",
       "      <td>0.7821806046759001</td>\n",
       "      <td>0.009387723516423153</td>\n",
       "      <td>0.782153575721328</td>\n",
       "      <td>0.010197708467562157</td>\n",
       "      <td>0.782061329646398</td>\n",
       "      <td>0.0036137425983929767</td>\n",
       "      <td>0.21789999999999998</td>\n",
       "      <td>0.002161018278497433</td>\n",
       "      <td>3.0667855739593506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.7794</td>\n",
       "      <td>0.005806892456383193</td>\n",
       "      <td>0.779410719564866</td>\n",
       "      <td>0.007686297602573202</td>\n",
       "      <td>0.779365994913634</td>\n",
       "      <td>0.009187877428490138</td>\n",
       "      <td>0.779352476635936</td>\n",
       "      <td>0.0066040476199763325</td>\n",
       "      <td>0.22060000000000002</td>\n",
       "      <td>0.005806892456383188</td>\n",
       "      <td>4.210824728012085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.7754</td>\n",
       "      <td>0.012577758146824089</td>\n",
       "      <td>0.7754958533299909</td>\n",
       "      <td>0.017177208871730264</td>\n",
       "      <td>0.7755717489536813</td>\n",
       "      <td>0.015639624134931793</td>\n",
       "      <td>0.7753895379719178</td>\n",
       "      <td>0.012675515821478077</td>\n",
       "      <td>0.2246</td>\n",
       "      <td>0.012577758146824103</td>\n",
       "      <td>5.235754489898682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.7648999999999999</td>\n",
       "      <td>0.005465345368775882</td>\n",
       "      <td>0.7648642129646994</td>\n",
       "      <td>0.012717819812598211</td>\n",
       "      <td>0.7649902206231625</td>\n",
       "      <td>0.008859987881757554</td>\n",
       "      <td>0.7648296698852362</td>\n",
       "      <td>0.006726841286232468</td>\n",
       "      <td>0.2351</td>\n",
       "      <td>0.00546534536877589</td>\n",
       "      <td>8.538753986358643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.010749883720301365</td>\n",
       "      <td>0.768278942741755</td>\n",
       "      <td>0.012044797702197081</td>\n",
       "      <td>0.7682174997996688</td>\n",
       "      <td>0.01378177507939997</td>\n",
       "      <td>0.7681835463450228</td>\n",
       "      <td>0.010938522990287877</td>\n",
       "      <td>0.2318</td>\n",
       "      <td>0.01074988372030135</td>\n",
       "      <td>11.427642822265625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.7658</td>\n",
       "      <td>0.01361322886019332</td>\n",
       "      <td>0.7658054314109666</td>\n",
       "      <td>0.014934148052851797</td>\n",
       "      <td>0.7658225566824736</td>\n",
       "      <td>0.01464987254005301</td>\n",
       "      <td>0.7657775018212829</td>\n",
       "      <td>0.013792151478570455</td>\n",
       "      <td>0.2342</td>\n",
       "      <td>0.01361322886019331</td>\n",
       "      <td>14.04838228225708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.7672</td>\n",
       "      <td>0.005192301994298889</td>\n",
       "      <td>0.7672034388336384</td>\n",
       "      <td>0.009001173036433316</td>\n",
       "      <td>0.7671936509509338</td>\n",
       "      <td>0.00938845732050479</td>\n",
       "      <td>0.7671412385899348</td>\n",
       "      <td>0.0064136852021451545</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.005192301994298869</td>\n",
       "      <td>16.851051330566406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"7\" valign=\"top\">50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7868</td>\n",
       "      <td>0.006099180272790759</td>\n",
       "      <td>0.7867056931747316</td>\n",
       "      <td>0.019244226533496393</td>\n",
       "      <td>0.7871017837530736</td>\n",
       "      <td>0.012253980337734012</td>\n",
       "      <td>0.7866555938893203</td>\n",
       "      <td>0.008117063117688271</td>\n",
       "      <td>0.2132</td>\n",
       "      <td>0.00609918027279076</td>\n",
       "      <td>4.812737464904785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.7858</td>\n",
       "      <td>0.009832598842625467</td>\n",
       "      <td>0.7857908234651574</td>\n",
       "      <td>0.017442568938975524</td>\n",
       "      <td>0.7860174980396399</td>\n",
       "      <td>0.012392599215518397</td>\n",
       "      <td>0.7857462633275552</td>\n",
       "      <td>0.010492747014927382</td>\n",
       "      <td>0.2142</td>\n",
       "      <td>0.009832598842625486</td>\n",
       "      <td>8.26944613456726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.7722</td>\n",
       "      <td>0.006942621983083937</td>\n",
       "      <td>0.7722982490547161</td>\n",
       "      <td>0.01684911328392826</td>\n",
       "      <td>0.7724053465625826</td>\n",
       "      <td>0.014224372369392746</td>\n",
       "      <td>0.772124570381914</td>\n",
       "      <td>0.00815226643911743</td>\n",
       "      <td>0.2278</td>\n",
       "      <td>0.006942621983083914</td>\n",
       "      <td>11.629748106002808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.0057436921923097635</td>\n",
       "      <td>0.7739217523746209</td>\n",
       "      <td>0.02068397509304568</td>\n",
       "      <td>0.7744451714982746</td>\n",
       "      <td>0.010699466242174606</td>\n",
       "      <td>0.7739283135337086</td>\n",
       "      <td>0.00833342315087377</td>\n",
       "      <td>0.2259</td>\n",
       "      <td>0.005743692192309755</td>\n",
       "      <td>18.394407749176025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.7719</td>\n",
       "      <td>0.010324243313676778</td>\n",
       "      <td>0.7719606562584062</td>\n",
       "      <td>0.016435042055454676</td>\n",
       "      <td>0.7720828167666935</td>\n",
       "      <td>0.01406888505728942</td>\n",
       "      <td>0.7718690664671278</td>\n",
       "      <td>0.010639469398295767</td>\n",
       "      <td>0.22810000000000002</td>\n",
       "      <td>0.010324243313676791</td>\n",
       "      <td>21.67050576210022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.7712000000000001</td>\n",
       "      <td>0.003544009029333871</td>\n",
       "      <td>0.7708864498459731</td>\n",
       "      <td>0.014031841910161045</td>\n",
       "      <td>0.7711561881911337</td>\n",
       "      <td>0.004993334132758241</td>\n",
       "      <td>0.7709629863670059</td>\n",
       "      <td>0.00810360804610026</td>\n",
       "      <td>0.2288</td>\n",
       "      <td>0.0035440090293338733</td>\n",
       "      <td>32.22256350517273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.7662</td>\n",
       "      <td>0.007426977851050858</td>\n",
       "      <td>0.7662058447241166</td>\n",
       "      <td>0.014156958861095149</td>\n",
       "      <td>0.7663027045099418</td>\n",
       "      <td>0.011617569114138686</td>\n",
       "      <td>0.7661322503525945</td>\n",
       "      <td>0.008546259028517222</td>\n",
       "      <td>0.2338</td>\n",
       "      <td>0.007426977851050853</td>\n",
       "      <td>44.09818410873413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"7\" valign=\"top\">100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7965</td>\n",
       "      <td>0.008334866525625935</td>\n",
       "      <td>0.7964565024002461</td>\n",
       "      <td>0.01870896741197395</td>\n",
       "      <td>0.7967902015736148</td>\n",
       "      <td>0.013681195992433665</td>\n",
       "      <td>0.7964002760980442</td>\n",
       "      <td>0.009373927778643204</td>\n",
       "      <td>0.20350000000000001</td>\n",
       "      <td>0.00833486652562595</td>\n",
       "      <td>6.642278671264648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.7856</td>\n",
       "      <td>0.005455272678794356</td>\n",
       "      <td>0.7856086066643233</td>\n",
       "      <td>0.01232406730186033</td>\n",
       "      <td>0.7856590136831392</td>\n",
       "      <td>0.01097928169335619</td>\n",
       "      <td>0.7855205773648524</td>\n",
       "      <td>0.006796774556842546</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.00545527267879434</td>\n",
       "      <td>12.099433422088623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.008883692925805117</td>\n",
       "      <td>0.7849468851496224</td>\n",
       "      <td>0.015380479554147713</td>\n",
       "      <td>0.7851517879332246</td>\n",
       "      <td>0.01079773975730835</td>\n",
       "      <td>0.7849413523657399</td>\n",
       "      <td>0.00956149657058383</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.008883692925805126</td>\n",
       "      <td>17.568209648132324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.7781</td>\n",
       "      <td>0.007312318373812782</td>\n",
       "      <td>0.7780566827429027</td>\n",
       "      <td>0.014094527695087915</td>\n",
       "      <td>0.7782080595074008</td>\n",
       "      <td>0.010554317153103456</td>\n",
       "      <td>0.7780246147236831</td>\n",
       "      <td>0.008342680972518049</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.007312318373812778</td>\n",
       "      <td>30.282498121261597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.7715000000000001</td>\n",
       "      <td>0.007971825386948695</td>\n",
       "      <td>0.7714780166748664</td>\n",
       "      <td>0.011657165055907921</td>\n",
       "      <td>0.7715620565199974</td>\n",
       "      <td>0.009033255938063766</td>\n",
       "      <td>0.7714696041777962</td>\n",
       "      <td>0.008379764185636844</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.007971825386948716</td>\n",
       "      <td>35.62034583091736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.7756</td>\n",
       "      <td>0.004445222154178589</td>\n",
       "      <td>0.775985627885732</td>\n",
       "      <td>0.030127490003945667</td>\n",
       "      <td>0.7766888988817101</td>\n",
       "      <td>0.021713711627517587</td>\n",
       "      <td>0.7755002871520824</td>\n",
       "      <td>0.006455041994209314</td>\n",
       "      <td>0.2244</td>\n",
       "      <td>0.004445222154178576</td>\n",
       "      <td>55.70591640472412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.7767999999999999</td>\n",
       "      <td>0.006723094525588667</td>\n",
       "      <td>0.7767473434831738</td>\n",
       "      <td>0.018024349350255823</td>\n",
       "      <td>0.7770626569906036</td>\n",
       "      <td>0.01090389770473711</td>\n",
       "      <td>0.7767055630525578</td>\n",
       "      <td>0.00824463900249838</td>\n",
       "      <td>0.22319999999999998</td>\n",
       "      <td>0.006723094525588646</td>\n",
       "      <td>82.05336236953735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Eficiencia  \\\n",
       "Numero de arboles Variables analizadas por nodo                       \n",
       "5                 10                                          0.768   \n",
       "                  50                                         0.7525   \n",
       "                  100                            0.7513999999999998   \n",
       "                  200                                        0.7476   \n",
       "                  250                                        0.7521   \n",
       "                  350                                         0.753   \n",
       "                  500                            0.7571000000000001   \n",
       "10                10                                         0.7814   \n",
       "                  50                                         0.7699   \n",
       "                  100                            0.7666000000000001   \n",
       "                  200                                        0.7644   \n",
       "                  250                                         0.763   \n",
       "                  350                                        0.7581   \n",
       "                  500                                        0.7652   \n",
       "20                10                                         0.7821   \n",
       "                  50                                         0.7794   \n",
       "                  100                                        0.7754   \n",
       "                  200                            0.7648999999999999   \n",
       "                  250                                        0.7682   \n",
       "                  350                                        0.7658   \n",
       "                  500                                        0.7672   \n",
       "50                10                                         0.7868   \n",
       "                  50                                         0.7858   \n",
       "                  100                                        0.7722   \n",
       "                  200                                        0.7741   \n",
       "                  250                                        0.7719   \n",
       "                  350                            0.7712000000000001   \n",
       "                  500                                        0.7662   \n",
       "100               10                                         0.7965   \n",
       "                  50                                         0.7856   \n",
       "                  100                                         0.785   \n",
       "                  200                                        0.7781   \n",
       "                  250                            0.7715000000000001   \n",
       "                  350                                        0.7756   \n",
       "                  500                            0.7767999999999999   \n",
       "\n",
       "                                                        Int_Eficiencia  \\\n",
       "Numero de arboles Variables analizadas por nodo                          \n",
       "5                 10                              0.007720103626247511   \n",
       "                  50                              0.005094114250779986   \n",
       "                  100                              0.00980408078302091   \n",
       "                  200                             0.008527602242131145   \n",
       "                  250                              0.00986458311334037   \n",
       "                  350                              0.00567450438364446   \n",
       "                  500                             0.005867708240872232   \n",
       "10                10                               0.00819999999999999   \n",
       "                  50                              0.003923009049186621   \n",
       "                  100                             0.006636264009214825   \n",
       "                  200                              0.01107429455992571   \n",
       "                  250                             0.002849561369754992   \n",
       "                  350                             0.002762245463386639   \n",
       "                  500                             0.008611620056644405   \n",
       "20                10                             0.0021610182784974332   \n",
       "                  50                              0.005806892456383193   \n",
       "                  100                             0.012577758146824089   \n",
       "                  200                             0.005465345368775882   \n",
       "                  250                             0.010749883720301365   \n",
       "                  350                              0.01361322886019332   \n",
       "                  500                             0.005192301994298889   \n",
       "50                10                              0.006099180272790759   \n",
       "                  50                              0.009832598842625467   \n",
       "                  100                             0.006942621983083937   \n",
       "                  200                            0.0057436921923097635   \n",
       "                  250                             0.010324243313676778   \n",
       "                  350                             0.003544009029333871   \n",
       "                  500                             0.007426977851050858   \n",
       "100               10                              0.008334866525625935   \n",
       "                  50                              0.005455272678794356   \n",
       "                  100                             0.008883692925805117   \n",
       "                  200                             0.007312318373812782   \n",
       "                  250                             0.007971825386948695   \n",
       "                  350                             0.004445222154178589   \n",
       "                  500                             0.006723094525588667   \n",
       "\n",
       "                                                       Sensibilidad  \\\n",
       "Numero de arboles Variables analizadas por nodo                       \n",
       "5                 10                             0.7681197522306458   \n",
       "                  50                             0.7527230379895022   \n",
       "                  100                            0.7517487781704586   \n",
       "                  200                             0.747646256213125   \n",
       "                  250                              0.75217275997439   \n",
       "                  350                            0.7529202636888145   \n",
       "                  500                            0.7573328054986118   \n",
       "10                10                             0.7811151267245141   \n",
       "                  50                             0.7700826063454782   \n",
       "                  100                             0.766612027848639   \n",
       "                  200                            0.7644767727277894   \n",
       "                  250                            0.7630091590720154   \n",
       "                  350                            0.7580381894170327   \n",
       "                  500                            0.7652475017315867   \n",
       "20                10                             0.7821806046759001   \n",
       "                  50                              0.779410719564866   \n",
       "                  100                            0.7754958533299909   \n",
       "                  200                            0.7648642129646994   \n",
       "                  250                             0.768278942741755   \n",
       "                  350                            0.7658054314109666   \n",
       "                  500                            0.7672034388336384   \n",
       "50                10                             0.7867056931747316   \n",
       "                  50                             0.7857908234651574   \n",
       "                  100                            0.7722982490547161   \n",
       "                  200                            0.7739217523746209   \n",
       "                  250                            0.7719606562584062   \n",
       "                  350                            0.7708864498459731   \n",
       "                  500                            0.7662058447241166   \n",
       "100               10                             0.7964565024002461   \n",
       "                  50                             0.7856086066643233   \n",
       "                  100                            0.7849468851496224   \n",
       "                  200                            0.7780566827429027   \n",
       "                  250                            0.7714780166748664   \n",
       "                  350                             0.775985627885732   \n",
       "                  500                            0.7767473434831738   \n",
       "\n",
       "                                                     Int_Sensibilidad  \\\n",
       "Numero de arboles Variables analizadas por nodo                         \n",
       "5                 10                              0.01562978505869847   \n",
       "                  50                              0.01465903924467677   \n",
       "                  100                            0.021133867588757342   \n",
       "                  200                            0.013888268288366612   \n",
       "                  250                             0.02173734488995919   \n",
       "                  350                             0.01337853231848005   \n",
       "                  500                            0.015199643787813905   \n",
       "10                10                             0.023098747024502226   \n",
       "                  50                             0.013380693239213183   \n",
       "                  100                            0.009765084156212465   \n",
       "                  200                            0.016308392524102815   \n",
       "                  250                            0.013230783291164994   \n",
       "                  350                            0.006355449240014822   \n",
       "                  500                             0.01502266030435888   \n",
       "20                10                             0.009387723516423153   \n",
       "                  50                             0.007686297602573202   \n",
       "                  100                            0.017177208871730264   \n",
       "                  200                            0.012717819812598211   \n",
       "                  250                            0.012044797702197081   \n",
       "                  350                            0.014934148052851797   \n",
       "                  500                            0.009001173036433316   \n",
       "50                10                             0.019244226533496393   \n",
       "                  50                             0.017442568938975524   \n",
       "                  100                             0.01684911328392826   \n",
       "                  200                             0.02068397509304568   \n",
       "                  250                            0.016435042055454676   \n",
       "                  350                            0.014031841910161045   \n",
       "                  500                            0.014156958861095149   \n",
       "100               10                              0.01870896741197395   \n",
       "                  50                              0.01232406730186033   \n",
       "                  100                            0.015380479554147713   \n",
       "                  200                            0.014094527695087915   \n",
       "                  250                            0.011657165055907921   \n",
       "                  350                            0.030127490003945667   \n",
       "                  500                            0.018024349350255823   \n",
       "\n",
       "                                                          Precision  \\\n",
       "Numero de arboles Variables analizadas por nodo                       \n",
       "5                 10                             0.7681596542808651   \n",
       "                  50                             0.7527088689318898   \n",
       "                  100                            0.7518335029234671   \n",
       "                  200                            0.7477293905545236   \n",
       "                  250                            0.7524474062046478   \n",
       "                  350                            0.7530517645337671   \n",
       "                  500                            0.7573130975779225   \n",
       "10                10                             0.7817450462702595   \n",
       "                  50                              0.769929780546923   \n",
       "                  100                            0.7666447204504659   \n",
       "                  200                             0.764534228641272   \n",
       "                  250                            0.7631271495858591   \n",
       "                  350                            0.7580451209602892   \n",
       "                  500                            0.7653437422369807   \n",
       "20                10                              0.782153575721328   \n",
       "                  50                              0.779365994913634   \n",
       "                  100                            0.7755717489536813   \n",
       "                  200                            0.7649902206231625   \n",
       "                  250                            0.7682174997996688   \n",
       "                  350                            0.7658225566824736   \n",
       "                  500                            0.7671936509509338   \n",
       "50                10                             0.7871017837530736   \n",
       "                  50                             0.7860174980396399   \n",
       "                  100                            0.7724053465625826   \n",
       "                  200                            0.7744451714982746   \n",
       "                  250                            0.7720828167666935   \n",
       "                  350                            0.7711561881911337   \n",
       "                  500                            0.7663027045099418   \n",
       "100               10                             0.7967902015736148   \n",
       "                  50                             0.7856590136831392   \n",
       "                  100                            0.7851517879332246   \n",
       "                  200                            0.7782080595074008   \n",
       "                  250                            0.7715620565199974   \n",
       "                  350                            0.7766888988817101   \n",
       "                  500                            0.7770626569906036   \n",
       "\n",
       "                                                        Int_Precision  \\\n",
       "Numero de arboles Variables analizadas por nodo                         \n",
       "5                 10                             0.014574833875643789   \n",
       "                  50                             0.015211762848628898   \n",
       "                  100                             0.01966142703793593   \n",
       "                  200                            0.011411926364915058   \n",
       "                  250                            0.016854080654819168   \n",
       "                  350                            0.008917174000705545   \n",
       "                  500                             0.01586270908163376   \n",
       "10                10                             0.012311369628205665   \n",
       "                  50                             0.016727362234699835   \n",
       "                  100                             0.00838794960707761   \n",
       "                  200                            0.015162802744504595   \n",
       "                  250                            0.009693778024068123   \n",
       "                  350                            0.006029379603136729   \n",
       "                  500                              0.0122889624633625   \n",
       "20                10                             0.010197708467562157   \n",
       "                  50                             0.009187877428490138   \n",
       "                  100                            0.015639624134931793   \n",
       "                  200                            0.008859987881757554   \n",
       "                  250                             0.01378177507939997   \n",
       "                  350                             0.01464987254005301   \n",
       "                  500                             0.00938845732050479   \n",
       "50                10                             0.012253980337734012   \n",
       "                  50                             0.012392599215518397   \n",
       "                  100                            0.014224372369392746   \n",
       "                  200                            0.010699466242174606   \n",
       "                  250                             0.01406888505728942   \n",
       "                  350                            0.004993334132758241   \n",
       "                  500                            0.011617569114138686   \n",
       "100               10                             0.013681195992433665   \n",
       "                  50                              0.01097928169335619   \n",
       "                  100                             0.01079773975730835   \n",
       "                  200                            0.010554317153103456   \n",
       "                  250                            0.009033255938063766   \n",
       "                  350                            0.021713711627517587   \n",
       "                  500                             0.01090389770473711   \n",
       "\n",
       "                                                            F-Score  \\\n",
       "Numero de arboles Variables analizadas por nodo                       \n",
       "5                 10                             0.7679411688287637   \n",
       "                  50                             0.7524621824742599   \n",
       "                  100                            0.7513772834842649   \n",
       "                  200                            0.7475769457935577   \n",
       "                  250                            0.7519870084943077   \n",
       "                  350                            0.7528922910437856   \n",
       "                  500                            0.7570625985865006   \n",
       "10                10                             0.7811502951516653   \n",
       "                  50                             0.7697670783783414   \n",
       "                  100                            0.7665825727163263   \n",
       "                  200                            0.7643534669970106   \n",
       "                  250                            0.7629241131588711   \n",
       "                  350                            0.7580245888116479   \n",
       "                  500                            0.7651559919002772   \n",
       "20                10                              0.782061329646398   \n",
       "                  50                              0.779352476635936   \n",
       "                  100                            0.7753895379719178   \n",
       "                  200                            0.7648296698852362   \n",
       "                  250                            0.7681835463450228   \n",
       "                  350                            0.7657775018212829   \n",
       "                  500                            0.7671412385899348   \n",
       "50                10                             0.7866555938893203   \n",
       "                  50                             0.7857462633275552   \n",
       "                  100                             0.772124570381914   \n",
       "                  200                            0.7739283135337086   \n",
       "                  250                            0.7718690664671278   \n",
       "                  350                            0.7709629863670059   \n",
       "                  500                            0.7661322503525945   \n",
       "100               10                             0.7964002760980442   \n",
       "                  50                             0.7855205773648524   \n",
       "                  100                            0.7849413523657399   \n",
       "                  200                            0.7780246147236831   \n",
       "                  250                            0.7714696041777962   \n",
       "                  350                            0.7755002871520824   \n",
       "                  500                            0.7767055630525578   \n",
       "\n",
       "                                                           Int_F-Score  \\\n",
       "Numero de arboles Variables analizadas por nodo                          \n",
       "5                 10                              0.008585429324470489   \n",
       "                  50                              0.005887323185144872   \n",
       "                  100                              0.01011591448388318   \n",
       "                  200                             0.008844526065819895   \n",
       "                  250                             0.011224627950828632   \n",
       "                  350                             0.007735303630441002   \n",
       "                  500                             0.006581461074606912   \n",
       "10                10                              0.011117979255308285   \n",
       "                  50                              0.006777102427305084   \n",
       "                  100                             0.006953935089289847   \n",
       "                  200                             0.011580764035632633   \n",
       "                  250                             0.005071631032582017   \n",
       "                  350                              0.00503602335595156   \n",
       "                  500                               0.0091950486287082   \n",
       "20                10                             0.0036137425983929767   \n",
       "                  50                             0.0066040476199763325   \n",
       "                  100                             0.012675515821478077   \n",
       "                  200                             0.006726841286232468   \n",
       "                  250                             0.010938522990287877   \n",
       "                  350                             0.013792151478570455   \n",
       "                  500                            0.0064136852021451545   \n",
       "50                10                              0.008117063117688271   \n",
       "                  50                              0.010492747014927382   \n",
       "                  100                              0.00815226643911743   \n",
       "                  200                              0.00833342315087377   \n",
       "                  250                             0.010639469398295767   \n",
       "                  350                              0.00810360804610026   \n",
       "                  500                             0.008546259028517222   \n",
       "100               10                              0.009373927778643204   \n",
       "                  50                              0.006796774556842546   \n",
       "                  100                              0.00956149657058383   \n",
       "                  200                             0.008342680972518049   \n",
       "                  250                             0.008379764185636844   \n",
       "                  350                             0.006455041994209314   \n",
       "                  500                              0.00824463900249838   \n",
       "\n",
       "                                                        Error_Prueba  \\\n",
       "Numero de arboles Variables analizadas por nodo                        \n",
       "5                 10                                           0.232   \n",
       "                  50                                          0.2475   \n",
       "                  100                                         0.2486   \n",
       "                  200                            0.25239999999999996   \n",
       "                  250                                         0.2479   \n",
       "                  350                                          0.247   \n",
       "                  500                                         0.2429   \n",
       "10                10                                          0.2186   \n",
       "                  50                             0.23010000000000003   \n",
       "                  100                            0.23340000000000002   \n",
       "                  200                            0.23559999999999998   \n",
       "                  250                                          0.237   \n",
       "                  350                                         0.2419   \n",
       "                  500                                         0.2348   \n",
       "20                10                             0.21789999999999998   \n",
       "                  50                             0.22060000000000002   \n",
       "                  100                                         0.2246   \n",
       "                  200                                         0.2351   \n",
       "                  250                                         0.2318   \n",
       "                  350                                         0.2342   \n",
       "                  500                                         0.2328   \n",
       "50                10                                          0.2132   \n",
       "                  50                                          0.2142   \n",
       "                  100                                         0.2278   \n",
       "                  200                                         0.2259   \n",
       "                  250                            0.22810000000000002   \n",
       "                  350                                         0.2288   \n",
       "                  500                                         0.2338   \n",
       "100               10                             0.20350000000000001   \n",
       "                  50                                          0.2144   \n",
       "                  100                                          0.215   \n",
       "                  200                                         0.2219   \n",
       "                  250                                         0.2285   \n",
       "                  350                                         0.2244   \n",
       "                  500                            0.22319999999999998   \n",
       "\n",
       "                                                             Int_error  \\\n",
       "Numero de arboles Variables analizadas por nodo                          \n",
       "5                 10                              0.007720103626247512   \n",
       "                  50                              0.005094114250780005   \n",
       "                  100                             0.009804080783020919   \n",
       "                  200                             0.008527602242131135   \n",
       "                  250                             0.009864583113340375   \n",
       "                  350                              0.00567450438364444   \n",
       "                  500                             0.005867708240872241   \n",
       "10                10                                            0.0082   \n",
       "                  50                              0.003923009049186607   \n",
       "                  100                              0.00663626400921482   \n",
       "                  200                             0.011074294559925703   \n",
       "                  250                            0.0028495613697549944   \n",
       "                  350                             0.002762245463386627   \n",
       "                  500                              0.00861162005664439   \n",
       "20                10                              0.002161018278497433   \n",
       "                  50                              0.005806892456383188   \n",
       "                  100                             0.012577758146824103   \n",
       "                  200                              0.00546534536877589   \n",
       "                  250                              0.01074988372030135   \n",
       "                  350                              0.01361322886019331   \n",
       "                  500                             0.005192301994298869   \n",
       "50                10                               0.00609918027279076   \n",
       "                  50                              0.009832598842625486   \n",
       "                  100                             0.006942621983083914   \n",
       "                  200                             0.005743692192309755   \n",
       "                  250                             0.010324243313676791   \n",
       "                  350                            0.0035440090293338733   \n",
       "                  500                             0.007426977851050853   \n",
       "100               10                               0.00833486652562595   \n",
       "                  50                               0.00545527267879434   \n",
       "                  100                             0.008883692925805126   \n",
       "                  200                             0.007312318373812778   \n",
       "                  250                             0.007971825386948716   \n",
       "                  350                             0.004445222154178576   \n",
       "                  500                             0.006723094525588646   \n",
       "\n",
       "                                                Tiempo de ejecución  \n",
       "Numero de arboles Variables analizadas por nodo                      \n",
       "5                 10                              2.736989736557007  \n",
       "                  50                             3.2297675609588623  \n",
       "                  100                             4.223835468292236  \n",
       "                  200                             5.480790138244629  \n",
       "                  250                              5.72574520111084  \n",
       "                  350                             6.676495552062988  \n",
       "                  500                             6.355423450469971  \n",
       "10                10                              2.811055898666382  \n",
       "                  50                             3.5221989154815674  \n",
       "                  100                             4.026188611984253  \n",
       "                  200                             5.784253120422363  \n",
       "                  250                            6.1896209716796875  \n",
       "                  350                             7.629929304122925  \n",
       "                  500                             9.305449962615967  \n",
       "20                10                             3.0667855739593506  \n",
       "                  50                              4.210824728012085  \n",
       "                  100                             5.235754489898682  \n",
       "                  200                             8.538753986358643  \n",
       "                  250                            11.427642822265625  \n",
       "                  350                             14.04838228225708  \n",
       "                  500                            16.851051330566406  \n",
       "50                10                              4.812737464904785  \n",
       "                  50                               8.26944613456726  \n",
       "                  100                            11.629748106002808  \n",
       "                  200                            18.394407749176025  \n",
       "                  250                             21.67050576210022  \n",
       "                  350                             32.22256350517273  \n",
       "                  500                             44.09818410873413  \n",
       "100               10                              6.642278671264648  \n",
       "                  50                             12.099433422088623  \n",
       "                  100                            17.568209648132324  \n",
       "                  200                            30.282498121261597  \n",
       "                  250                             35.62034583091736  \n",
       "                  350                             55.70591640472412  \n",
       "                  500                             82.05336236953735  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal recurrente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Acc, IntAcc, Sen, IntSen, Pre, IntPre, f, IntF, error, stdError, tiempo = LRC(1, 'liblinear', impresion = True)\n",
    "print('Eficiencia',Acc, ' Int_Eficiencia', IntAcc,' Sensibilidad', Sen, ' Int_Sensibilidad',IntSen,' Precision', Pre, ' Int_Precision',IntPre,' F-Score', f, ' Int_F-Score',IntF,' Error_Prueba', error,' Int_Error', stdError,' Tiempo ejecución', tiempo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
